{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vCgy_uHgI9jH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2575d4d-7eda-4454-89da-6d15f1270cb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Python 3.11.12\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: serpapi in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: jina in /usr/local/lib/python3.11/dist-packages (3.34.0)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-grpc>=0.35b0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.53b1)\n",
            "Requirement already satisfied: docarray>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from jina) (0.41.0)\n",
            "Requirement already satisfied: pathspec in /usr/local/lib/python3.11/dist-packages (from jina) (0.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from jina) (2.0.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-prometheus>=0.33b0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.53b1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from jina) (15.0.1)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from jina) (24.1.0)\n",
            "Requirement already satisfied: jcloud>=0.0.35 in /usr/local/lib/python3.11/dist-packages (from jina) (0.3)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.33b0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.53b1)\n",
            "Requirement already satisfied: grpcio<=1.68.0,>=1.46.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.32.1)\n",
            "Requirement already satisfied: grpcio-reflection<=1.68.0,>=1.46.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.68.0)\n",
            "Requirement already satisfied: pydantic<3.0.0 in /usr/local/lib/python3.11/dist-packages (from jina) (2.11.3)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.32.1)\n",
            "Requirement already satisfied: fastapi>=0.76.0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.115.12)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-aiohttp-client>=0.33b0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.53b1)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from jina) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from jina) (3.18.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from jina) (5.29.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from jina) (24.2)\n",
            "Requirement already satisfied: prometheus_client>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.21.1)\n",
            "Requirement already satisfied: jina-hubble-sdk>=0.30.4 in /usr/local/lib/python3.11/dist-packages (from jina) (0.39.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from jina) (3.11.15)\n",
            "Requirement already satisfied: opentelemetry-api>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.32.1)\n",
            "Requirement already satisfied: uvloop in /usr/local/lib/python3.11/dist-packages (from jina) (0.21.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from jina) (0.0.20)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.32.1)\n",
            "Requirement already satisfied: grpcio-health-checking<=1.68.0,>=1.46.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.68.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from jina) (6.0.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.9 in /usr/local/lib/python3.11/dist-packages (from jina) (1.26.20)\n",
            "Requirement already satisfied: uvicorn<=0.23.1 in /usr/local/lib/python3.11/dist-packages (from jina) (0.23.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.13.2)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.11/dist-packages (from docarray>=0.16.4->jina) (3.10.16)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from docarray>=0.16.4->jina) (13.9.4)\n",
            "Requirement already satisfied: types-requests>=2.28.11.6 in /usr/local/lib/python3.11/dist-packages (from docarray>=0.16.4->jina) (2.31.0.6)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from docarray>=0.16.4->jina) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.76.0->jina) (0.46.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from jcloud>=0.0.35->jina) (1.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (1.19.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from jina-hubble-sdk>=0.30.4->jina) (8.6.1)\n",
            "Requirement already satisfied: python-jose in /usr/local/lib/python3.11/dist-packages (from jina-hubble-sdk>=0.30.4->jina) (3.4.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.12.0->jina) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp>=1.12.0->jina) (1.32.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina) (0.53b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina) (1.17.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.33b0->jina) (0.53b1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.33b0->jina) (3.8.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0->jina) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0->jina) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0->jina) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn<=0.23.1->jina) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<=0.23.1->jina) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->jina-hubble-sdk>=0.30.4->jina) (3.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray>=0.16.4->jina) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray>=0.16.4->jina) (2.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.76.0->jina) (4.9.0)\n",
            "Requirement already satisfied: types-urllib3 in /usr/local/lib/python3.11/dist-packages (from types-requests>=2.28.11.6->docarray>=0.16.4->jina) (1.26.25.14)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->docarray>=0.16.4->jina) (1.0.0)\n",
            "Requirement already satisfied: ecdsa!=0.15 in /usr/local/lib/python3.11/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina) (0.19.1)\n",
            "Requirement already satisfied: rsa!=4.1.1,!=4.4,<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina) (0.4.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.76.0->jina) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray>=0.16.4->jina) (0.1.2)\n",
            "/bin/bash: line 1: nvidia-smi: command not found\n",
            "Python 3.11.12\n",
            "Requirement already satisfied: google-search-results in /usr/local/lib/python3.11/dist-packages (2.4.2)\n",
            "Requirement already satisfied: serpapi in /usr/local/lib/python3.11/dist-packages (0.1.5)\n",
            "Requirement already satisfied: jina in /usr/local/lib/python3.11/dist-packages (3.34.0)\n",
            "Requirement already satisfied: pinecone-client in /usr/local/lib/python3.11/dist-packages (6.0.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-grpc>=0.35b0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.53b1)\n",
            "Requirement already satisfied: docarray>=0.16.4 in /usr/local/lib/python3.11/dist-packages (from jina) (0.41.0)\n",
            "Requirement already satisfied: pathspec in /usr/local/lib/python3.11/dist-packages (from jina) (0.12.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from jina) (2.0.2)\n",
            "Requirement already satisfied: opentelemetry-exporter-prometheus>=0.33b0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.53b1)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.11/dist-packages (from jina) (15.0.1)\n",
            "Requirement already satisfied: aiofiles in /usr/local/lib/python3.11/dist-packages (from jina) (24.1.0)\n",
            "Requirement already satisfied: jcloud>=0.0.35 in /usr/local/lib/python3.11/dist-packages (from jina) (0.3)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.33b0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.53b1)\n",
            "Requirement already satisfied: grpcio<=1.68.0,>=1.46.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.68.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.32.1)\n",
            "Requirement already satisfied: grpcio-reflection<=1.68.0,>=1.46.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.68.0)\n",
            "Requirement already satisfied: pydantic<3.0.0 in /usr/local/lib/python3.11/dist-packages (from jina) (2.11.3)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.32.1)\n",
            "Requirement already satisfied: fastapi>=0.76.0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.115.12)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-aiohttp-client>=0.33b0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.53b1)\n",
            "Requirement already satisfied: docker in /usr/local/lib/python3.11/dist-packages (from jina) (7.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from jina) (3.18.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from jina) (5.29.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from jina) (24.2)\n",
            "Requirement already satisfied: prometheus_client>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from jina) (0.21.1)\n",
            "Requirement already satisfied: jina-hubble-sdk>=0.30.4 in /usr/local/lib/python3.11/dist-packages (from jina) (0.39.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from jina) (3.11.15)\n",
            "Requirement already satisfied: opentelemetry-api>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.32.1)\n",
            "Requirement already satisfied: uvloop in /usr/local/lib/python3.11/dist-packages (from jina) (0.21.0)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (from jina) (0.0.20)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.32.1)\n",
            "Requirement already satisfied: grpcio-health-checking<=1.68.0,>=1.46.0 in /usr/local/lib/python3.11/dist-packages (from jina) (1.68.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from jina) (6.0.2)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.25.9 in /usr/local/lib/python3.11/dist-packages (from jina) (1.26.20)\n",
            "Requirement already satisfied: uvicorn<=0.23.1 in /usr/local/lib/python3.11/dist-packages (from jina) (0.23.1)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone-client) (4.13.2)\n",
            "Requirement already satisfied: orjson>=3.8.2 in /usr/local/lib/python3.11/dist-packages (from docarray>=0.16.4->jina) (3.10.16)\n",
            "Requirement already satisfied: rich>=13.1.0 in /usr/local/lib/python3.11/dist-packages (from docarray>=0.16.4->jina) (13.9.4)\n",
            "Requirement already satisfied: types-requests>=2.28.11.6 in /usr/local/lib/python3.11/dist-packages (from docarray>=0.16.4->jina) (2.31.0.6)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from docarray>=0.16.4->jina) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi>=0.76.0->jina) (0.46.2)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from jcloud>=0.0.35->jina) (1.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->jina) (1.19.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from jina-hubble-sdk>=0.30.4->jina) (8.6.1)\n",
            "Requirement already satisfied: python-jose in /usr/local/lib/python3.11/dist-packages (from jina-hubble-sdk>=0.30.4->jina) (3.4.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-api>=1.12.0->jina) (1.2.18)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp>=1.12.0->jina) (1.32.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-proto==1.32.1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.13.0->jina) (1.32.1)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina) (0.53b1)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina) (0.53b1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-aiohttp-client>=0.33b0->jina) (1.17.2)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.53b1 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-fastapi>=0.33b0->jina) (0.53b1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.11/dist-packages (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.33b0->jina) (3.8.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0->jina) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0->jina) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0->jina) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone-client) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn<=0.23.1->jina) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn<=0.23.1->jina) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->jina-hubble-sdk>=0.30.4->jina) (3.21.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray>=0.16.4->jina) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.1.0->docarray>=0.16.4->jina) (2.18.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi>=0.76.0->jina) (4.9.0)\n",
            "Requirement already satisfied: types-urllib3 in /usr/local/lib/python3.11/dist-packages (from types-requests>=2.28.11.6->docarray>=0.16.4->jina) (1.26.25.14)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->docarray>=0.16.4->jina) (1.0.0)\n",
            "Requirement already satisfied: ecdsa!=0.15 in /usr/local/lib/python3.11/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina) (0.19.1)\n",
            "Requirement already satisfied: rsa!=4.1.1,!=4.4,<5.0,>=4.0 in /usr/local/lib/python3.11/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina) (4.9.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from python-jose->jina-hubble-sdk>=0.30.4->jina) (0.4.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi>=0.76.0->jina) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.1.0->docarray>=0.16.4->jina) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install google-search-results serpapi jina pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall pinecone-client -y\n",
        "!pip install pinecone\n",
        "!pip install pinecone --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydgdEj_XO8Eo",
        "outputId": "5b9387a6-fe2d-4be5-e7c7-6872c07fa316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pinecone-client 6.0.0\n",
            "Uninstalling pinecone-client-6.0.0:\n",
            "  Successfully uninstalled pinecone-client-6.0.0\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.13.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (1.26.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.13.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (1.26.20)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "source": [
        "# ✅ Install latest SDK\n",
        "!pip uninstall -y pinecone-client\n",
        "!pip install --upgrade pinecone\n",
        "!pip install pinecone\n",
        "\n",
        "# ✅ Set keys\n",
        "import os\n",
        "os.environ[\"PINECONE_API_KEY\"] = \"*******************************************************\"\n",
        "\n",
        "# ✅ Setup Pinecone\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Initialize Pinecone with API key\n",
        "pc = Pinecone(api_key=os.environ[\"PINECONE_API_KEY\"])\n",
        "\n",
        "index_name = \"indian-tax-chatbot\"\n",
        "dimension = 1536\n",
        "\n",
        "# Try creating the index only if it doesn't already exist\n",
        "try:\n",
        "    if index_name not in pc.list_indexes().names():\n",
        "        pc.create_index(\n",
        "            name=index_name,\n",
        "            dimension=dimension,\n",
        "            metric=\"cosine\",\n",
        "            spec=ServerlessSpec(\n",
        "                cloud=\"aws\",\n",
        "                region=\"us-east-1\"\n",
        "            )\n",
        "        )\n",
        "        print(f\"✅ Index '{index_name}' created.\")\n",
        "    else:\n",
        "        print(f\"ℹ️ Index '{index_name}' already exists.\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error creating/checking index: {e}\")\n",
        "\n",
        "# Connect to the index (if it exists)\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "print(f\"✅ Connected to index '{index_name}'.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1JWKrlDiMm_",
        "outputId": "1a7eccaa-083a-4735-8790-e3eb3c5ebe98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: pinecone-client 3.0.0\n",
            "Uninstalling pinecone-client-3.0.0:\n",
            "  Successfully uninstalled pinecone-client-3.0.0\n",
            "Collecting pinecone\n",
            "  Downloading pinecone-6.0.2-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.13.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "Downloading pinecone-6.0.2-py3-none-any.whl (421 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m421.9/421.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pinecone\n",
            "Successfully installed pinecone-6.0.2\n",
            "Requirement already satisfied: pinecone in /usr/local/lib/python3.11/dist-packages (6.0.2)\n",
            "Requirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2025.1.31)\n",
            "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in /usr/local/lib/python3.11/dist-packages (from pinecone) (0.0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.11/dist-packages (from pinecone) (4.13.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from pinecone) (2.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
            "ℹ️ Index 'indian-tax-chatbot' already exists.\n",
            "✅ Connected to index 'indian-tax-chatbot'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai pinecone-client python-dotenv requests\n",
        "!npm install -g localtunnel"
      ],
      "metadata": {
        "id": "kaCziaJEbkbC",
        "outputId": "fc37d2c7-1677-4a56-870a-0aca8ffd989f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "changed 22 packages in 747ms\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. First clean up existing installations\n",
        "!pip uninstall -y pinecone-client pinecone > /dev/null 2>&1\n",
        "\n",
        "# 2. Install the correct versions\n",
        "!pip install -q pinecone-client==2.2.2  # Specific stable version\n",
        "\n",
        "# 3. Verify installation\n",
        "!pip show pinecone-client"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DeSIQQgRi-Ou",
        "outputId": "62e1e9bd-0843-467e-ce76-9a8ff212ab52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/179.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.1/179.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/313.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hName: pinecone-client\n",
            "Version: 2.2.2\n",
            "Summary: Pinecone client and SDK\n",
            "Home-page: https://www.pinecone.io/\n",
            "Author: Pinecone Systems, Inc.\n",
            "Author-email: support@pinecone.io\n",
            "License: Proprietary License\n",
            "Location: /usr/local/lib/python3.11/dist-packages\n",
            "Requires: dnspython, loguru, numpy, python-dateutil, pyyaml, requests, tqdm, typing-extensions, urllib3\n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installations (run this first)\n",
        "!pip install -q google-generativeai pinecone-client python-dotenv requests\n",
        "!npm install -g localtunnel\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNbp6s-KiB9Q",
        "outputId": "6ab66815-82b1-49e7-d909-857a45550acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "changed 22 packages in 4s\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "import json\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from pinecone import Pinecone, Index # Import Pinecone and Index directly\n",
        "\n",
        "# Initialize APIs\n",
        "load_dotenv()\n",
        "\n",
        "# ===== REPLACE THESE =====\n",
        "PINECONE_API_KEY = \"*******************************************************\"\n",
        "GOOGLE_API_KEY = \"*******************************************************\"\n",
        "SERPER_API_KEY = \"*******************************************************\"\n",
        "# =========================\n",
        "\n",
        "# Configure Gemini\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY) # Use PINECONE_API_KEY here\n",
        "index_name = \"indian-tax-chatbot\" # Define index_name here\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Check if index exists and create if necessary (You might already have this logic elsewhere)\n",
        "# ... (your index creation/checking code) ...\n",
        "\n",
        "class IndianTaxChatbot:\n",
        "    def __init__(self):\n",
        "        self.user_id = None\n",
        "        self.current_context = {}\n",
        "\n",
        "    def set_user(self, user_id):\n",
        "        self.user_id = user_id\n",
        "        self._load_user_context()\n",
        "\n",
        "    def _load_user_context(self):\n",
        "        if self.user_id:\n",
        "            try:\n",
        "                results = index.fetch(ids=[self.user_id])\n",
        "                if results and self.user_id in results['vectors']:\n",
        "                    self.current_context = results['vectors'][self.user_id]['metadata']\n",
        "                else:\n",
        "                    self.current_context = {\n",
        "                        \"income_sources\": [],\n",
        "                        \"investments\": [],\n",
        "                        \"deductions\": [],\n",
        "                        \"family_status\": \"\",\n",
        "                        \"dependents\": 0,\n",
        "                        \"housing\": \"\",\n",
        "                        \"tax_slab\": \"\",\n",
        "                        \"previous_queries\": []\n",
        "                    }\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading context: {e}\")\n",
        "                self.current_context = {\n",
        "                    \"income_sources\": [],\n",
        "                    \"investments\": [],\n",
        "                    \"deductions\": [],\n",
        "                    \"family_status\": \"\",\n",
        "                    \"dependents\": 0,\n",
        "                    \"housing\": \"\",\n",
        "                    \"tax_slab\": \"\",\n",
        "                    \"previous_queries\": []\n",
        "                }\n",
        "\n",
        "    def _save_context(self):\n",
        "        if self.user_id:\n",
        "            try:\n",
        "                embedding = genai.embed_content(\n",
        "                    model=\"models/embedding-001\",\n",
        "                    content=self.user_id,\n",
        "                    task_type=\"retrieval_document\"\n",
        "                )[\"embedding\"]\n",
        "\n",
        "                index.upsert(vectors=[{\n",
        "                    \"id\": self.user_id,\n",
        "                    \"values\": embedding,\n",
        "                    \"metadata\": self.current_context\n",
        "                }])\n",
        "            except Exception as e:\n",
        "                print(f\"Error saving context: {e}\")\n",
        "\n",
        "    # ... (rest of your chatbot class code) ...\n",
        "\n",
        "\n",
        "# ===== TEST THE CHATBOT =====\n",
        "chatbot = IndianTaxChatbot()\n",
        "chatbot.set_user(\"demo_user_1\")\n",
        "\n",
        "# ... (rest of your test code) ..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "K0lveRCLoJTp",
        "outputId": "76e5f902-5276-4854-d9cf-d71f286c1de7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "The official Pinecone python package has been renamed from `pinecone-client` to `pinecone`. Please remove `pinecone-client` from your project dependencies and add `pinecone` instead. See the README at https://github.com/pinecone-io/pinecone-python-client for more information on using the python SDK.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d0b9a31ebe6f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpinecone\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPinecone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m \u001b[0;31m# Import Pinecone and Index directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Initialize APIs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pinecone/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \"\"\"\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m raise Exception(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"The official Pinecone python package has been renamed from `pinecone-client` to `pinecone`. Please remove `pinecone-client` from your project dependencies and add `pinecone` instead. See the README at https://github.com/pinecone-io/pinecone-python-client for more information on using the python SDK.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n",
            "\u001b[0;31mException\u001b[0m: The official Pinecone python package has been renamed from `pinecone-client` to `pinecone`. Please remove `pinecone-client` from your project dependencies and add `pinecone` instead. See the README at https://github.com/pinecone-io/pinecone-python-client for more information on using the python SDK."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === API TEST CELL === (Add this after Cell 1)\n",
        "def test_apis():\n",
        "    print(\"=== Testing APIs ===\")\n",
        "\n",
        "    # Test Gemini\n",
        "    try:\n",
        "        test_response = model.generate_content(\"What is 2+2?\")\n",
        "        print(f\"✅ Gemini working. Response: {test_response.text}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Gemini failed: {str(e)}\")\n",
        "        if \"403\" in str(e):\n",
        "            print(\"Fix: Enable API at https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com\")\n",
        "\n",
        "    # Test Pinecone\n",
        "    try:\n",
        "        stats = index.describe_index_stats()\n",
        "        print(f\"✅ Pinecone working. Stats: {stats}\")\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Pinecone failed: {str(e)}\")\n",
        "\n",
        "test_apis()  # Run the tests"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joabZIS4oytZ",
        "outputId": "4a1d3b2a-3a05-48df-d25f-554e61e2fe5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Testing APIs ===\n",
            "❌ Gemini failed: name 'model' is not defined\n",
            "❌ Pinecone failed: name 'index' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === CLEANUP CELL === (Run this first if errors persist)\n",
        "!pip uninstall -y google-generativeai pinecone-client\n",
        "!pip install -q google-generativeai pinecone-client==3.0.0\n",
        "print(\"✅ Packages reinstalled - restart runtime and try again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jjBlwZdkVst",
        "outputId": "1c26f8ac-7678-4743-9d7d-d845e0b0c759"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: google-generativeai 0.8.4\n",
            "Uninstalling google-generativeai-0.8.4:\n",
            "  Successfully uninstalled google-generativeai-0.8.4\n",
            "Found existing installation: pinecone-client 3.0.0\n",
            "Uninstalling pinecone-client-3.0.0:\n",
            "  Successfully uninstalled pinecone-client-3.0.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h✅ Packages reinstalled - restart runtime and try again\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installations (run this first)\n",
        "!pip install -q google-generativeai pinecone-client==3.0.0 python-dotenv requests\n",
        "!npm install -g localtunnel\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-CDpzkhjsfp",
        "outputId": "b02349d1-813c-40de-f15d-629624bff035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "changed 22 packages in 997ms\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, completely clean up existing installations\n",
        "!pip uninstall -y pinecone-client pinecone > /dev/null 2>&1\n",
        "!pip install -q google-generativeai pinecone python-dotenv requests"
      ],
      "metadata": {
        "id": "Q8WC9MVekTd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "import json\n",
        "from datetime import datetime\n",
        "import requests\n",
        "from pinecone import Pinecone\n",
        "\n",
        "# ===== API KEYS =====\n",
        "PINECONE_API_KEY = \"*******************************************************\"\n",
        "GOOGLE_API_KEY = \"*******************************************************\"\n",
        "\n",
        "# Initialize APIs\n",
        "try:\n",
        "    # Configure Gemini\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "\n",
        "    # Initialize Pinecone (correct way for latest version)\n",
        "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "    index_name = \"indian-tax-chatbot\"\n",
        "\n",
        "    # Check if index exists\n",
        "    if index_name not in pc.list_indexes().names():\n",
        "        pc.create_index(\n",
        "            name=index_name,\n",
        "            dimension=768,  # Gemini embeddings size\n",
        "            metric=\"cosine\",\n",
        "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "        )\n",
        "        print(f\"✅ Created new index: {index_name}\")\n",
        "    else:\n",
        "        print(f\"ℹ️ Using existing index: {index_name}\")\n",
        "\n",
        "    index = pc.Index(index_name)\n",
        "    print(\"✅ APIs initialized successfully\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Initialization failed: {str(e)}\")\n",
        "    raise\n",
        "\n",
        "# Enhanced Chatbot Class\n",
        "class IndianTaxChatbot:\n",
        "    def __init__(self):\n",
        "        self.user_id = None\n",
        "        self.current_context = {\n",
        "            \"income_sources\": [],\n",
        "            \"investments\": [],\n",
        "            \"deductions\": [],\n",
        "            \"family_status\": \"\",\n",
        "            \"dependents\": 0,\n",
        "            \"housing\": \"\",\n",
        "            \"tax_slab\": \"\",\n",
        "            \"previous_queries\": []\n",
        "        }\n",
        "\n",
        "    def set_user(self, user_id):\n",
        "        self.user_id = user_id\n",
        "        self._load_user_context()\n",
        "\n",
        "    def _load_user_context(self):\n",
        "        if not self.user_id:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            results = index.fetch(ids=[self.user_id])\n",
        "            if results and self.user_id in results['vectors']:\n",
        "                self.current_context = results['vectors'][self.user_id]['metadata']\n",
        "                print(f\"✅ Loaded context for user {self.user_id}\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Context load error: {str(e)}\")\n",
        "\n",
        "    def _save_context(self):\n",
        "        if not self.user_id:\n",
        "            return\n",
        "\n",
        "        try:\n",
        "            embedding = genai.embed_content(\n",
        "                model=\"models/embedding-001\",\n",
        "                content=json.dumps(self.current_context),\n",
        "                task_type=\"retrieval_document\"\n",
        "            )[\"embedding\"]\n",
        "\n",
        "            index.upsert(vectors=[{\n",
        "                \"id\": self.user_id,\n",
        "                \"values\": embedding,\n",
        "                \"metadata\": self.current_context\n",
        "            }])\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Context save error: {str(e)}\")\n",
        "\n",
        "# === TEST CODE ===\n",
        "if __name__ == \"__main__\":\n",
        "    # Test APIs\n",
        "    try:\n",
        "        print(\"\\n=== Testing APIs ===\")\n",
        "        # Test Gemini\n",
        "        test_response = model.generate_content(\"What is 2+2?\")\n",
        "        print(f\"✅ Gemini test passed. Response: {test_response.text}\")\n",
        "\n",
        "        # Test Pinecone\n",
        "        stats = index.describe_index_stats()\n",
        "        print(f\"✅ Pinecone test passed. Index stats: {stats}\")\n",
        "\n",
        "        # Initialize and test chatbot\n",
        "        print(\"\\n=== Testing Chatbot ===\")\n",
        "        chatbot = IndianTaxChatbot()\n",
        "        chatbot.set_user(\"demo_user_1\")\n",
        "\n",
        "        # Set sample profile\n",
        "        chatbot.current_context.update({\n",
        "            \"income_sources\": [\"Salary\", \"Freelance\"],\n",
        "            \"investments\": [\"PPF\"],\n",
        "            \"family_status\": \"Married\",\n",
        "            \"dependents\": 1\n",
        "        })\n",
        "\n",
        "        print(\"✅ Chatbot initialized successfully\")\n",
        "        print(\"\\nSample profile:\", json.dumps(chatbot.current_context, indent=2))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\n❌ Testing failed: {str(e)}\")\n",
        "        print(\"Possible fixes:\")\n",
        "        print(\"1. Verify API keys are correct\")\n",
        "        print(\"2. Check API enablement at:\")\n",
        "        print(\"   - Gemini: https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com\")\n",
        "        print(\"   - Pinecone: https://app.pinecone.io\")\n",
        "        print(\"3. Restart runtime and try again\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "F5a5ixlmqLxd",
        "outputId": "59e5a752-7c30-427f-c29d-bf241b3ffd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ Using existing index: indian-tax-chatbot\n",
            "✅ APIs initialized successfully\n",
            "\n",
            "=== Testing APIs ===\n",
            "\n",
            "❌ Testing failed: 404 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: models/gemini-pro is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.\n",
            "Possible fixes:\n",
            "1. Verify API keys are correct\n",
            "2. Check API enablement at:\n",
            "   - Gemini: https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com\n",
            "   - Pinecone: https://app.pinecone.io\n",
            "3. Restart runtime and try again\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tornado.access:404 POST /v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 6782.44ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y google-generativeai > /dev/null 2>&1\n",
        "!pip install -q --upgrade google-generativeai\n",
        "# Imports\n",
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import json\n",
        "\n",
        "# ===== API KEYS =====\n",
        "PINECONE_API_KEY = \"*******************************************************\"\n",
        "GOOGLE_API_KEY = \"*******************************************************\"\n",
        "\n",
        "# Initialize Gemini (Updated for July 2024)\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-latest')  # Updated model name\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index_name = \"indian-tax-chatbot\"\n",
        "\n",
        "if index_name not in pc.list_indexes().names():\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "    print(f\"✅ Created index: {index_name}\")\n",
        "else:\n",
        "    print(f\"ℹ️ Using existing index: {index_name}\")\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Test APIs\n",
        "try:\n",
        "    # Test Gemini\n",
        "    response = model.generate_content(\"What is 2+2?\")\n",
        "    print(\"✅ Gemini test passed:\", response.text)\n",
        "\n",
        "    # Test Pinecone\n",
        "    stats = index.describe_index_stats()\n",
        "    print(\"✅ Pinecone test passed:\", stats)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Test failed: {str(e)}\")\n",
        "    if \"404\" in str(e):\n",
        "        print(\"IMPORTANT: Make sure you're using the latest model name\")\n",
        "        print(\"Current correct model: 'gemini-1.5-pro-latest'\")\n",
        "    print(\"Full troubleshooting:\")\n",
        "    print(\"1. Verify API key at https://makersuite.google.com/app/apikey\")\n",
        "    print(\"2. Enable API: https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com\")\n",
        "    print(\"3. Restart runtime after making changes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "gjHGAcqQrrzc",
        "outputId": "21102620-fb2e-467b-c0af-18141879dd3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ℹ️ Using existing index: indian-tax-chatbot\n",
            "✅ Gemini test passed: 2 + 2 = 4\n",
            "\n",
            "✅ Pinecone test passed: {'dimension': 1536,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {},\n",
            " 'total_vector_count': 0,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, ensure all required imports and initializations are present\n",
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone\n",
        "import json\n",
        "\n",
        "# Initialize Gemini (must be in the same cell or runtime)\n",
        "genai.configure(api_key=\"*******************************************************\")  # Your actual key\n",
        "\n",
        "# Initialize Pinecone connection\n",
        "pc = Pinecone(api_key=\"*******************************************************\")\n",
        "index = pc.Index(\"indian-tax-chatbot\")\n",
        "\n",
        "# Sample tax data to add\n",
        "tax_data = [\n",
        "    {\n",
        "        \"id\": \"sec80c\",\n",
        "        \"text\": \"Section 80C allows ₹1.5L deduction for investments like PPF, ELSS, NSC, etc.\",\n",
        "        \"metadata\": {\n",
        "            \"section\": \"80C\",\n",
        "            \"max_amount\": 150000,\n",
        "            \"applicable_to\": [\"individual\", \"huf\"],\n",
        "            \"year\": 2024\n",
        "        }\n",
        "    },\n",
        "    {\n",
        "        \"id\": \"sec80d\",\n",
        "        \"text\": \"Section 80D provides health insurance deductions (₹25K-₹50K based on age)\",\n",
        "        \"metadata\": {\n",
        "            \"section\": \"80D\",\n",
        "            \"max_amount\": 50000,\n",
        "            \"applicable_to\": [\"individual\", \"huf\"],\n",
        "            \"year\": 2024\n",
        "        }\n",
        "    }\n",
        "]\n",
        "\n",
        "# Store data in Pinecone\n",
        "for item in tax_data:\n",
        "    try:\n",
        "        # Generate embedding\n",
        "        embedding = genai.embed_content(\n",
        "            model=\"models/embedding-001\",\n",
        "            content=item[\"text\"],\n",
        "            task_type=\"retrieval_document\"\n",
        "        )[\"embedding\"]\n",
        "\n",
        "        # Upsert to Pinecone\n",
        "        index.upsert(vectors=[{\n",
        "            \"id\": item[\"id\"],\n",
        "            \"values\": embedding,\n",
        "            \"metadata\": item[\"metadata\"]\n",
        "        }])\n",
        "        print(f\"Added: {item['id']}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to add {item['id']}: {str(e)}\")\n",
        "\n",
        "print(f\"\\n✅ Successfully added {len(tax_data)} tax provisions\")\n",
        "print(\"Current index stats:\", index.describe_index_stats())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "K57_s4-ouCUG",
        "outputId": "f9a1e796-2694-4c8b-84ee-e339bcbbe754"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to add sec80c: (400)\n",
            "Reason: Bad Request\n",
            "HTTP response headers: HTTPHeaderDict({'Date': 'Sat, 19 Apr 2025 16:04:09 GMT', 'Content-Type': 'application/json', 'Content-Length': '103', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '35', 'x-pinecone-request-id': '7387319726410024638', 'x-envoy-upstream-service-time': '17', 'server': 'envoy'})\n",
            "HTTP response body: {\"code\":3,\"message\":\"Vector dimension 768 does not match the dimension of the index 1536\",\"details\":[]}\n",
            "\n",
            "Failed to add sec80d: (400)\n",
            "Reason: Bad Request\n",
            "HTTP response headers: HTTPHeaderDict({'Date': 'Sat, 19 Apr 2025 16:04:10 GMT', 'Content-Type': 'application/json', 'Content-Length': '103', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '20', 'x-pinecone-request-id': '4358674475686956692', 'x-envoy-upstream-service-time': '21', 'server': 'envoy'})\n",
            "HTTP response body: {\"code\":3,\"message\":\"Vector dimension 768 does not match the dimension of the index 1536\",\"details\":[]}\n",
            "\n",
            "\n",
            "✅ Successfully added 2 tax provisions\n",
            "Current index stats: {'dimension': 1536,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {},\n",
            " 'total_vector_count': 0,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean install packages\n",
        "!pip uninstall -y pinecone-client pinecone > /dev/null 2>&1\n",
        "!pip install -q google-generativeai pinecone python-dotenv\n",
        "\n",
        "# IMPORTANT: Restart runtime now (Runtime → Restart runtime)\n",
        "# Click this after running this cell"
      ],
      "metadata": {
        "id": "Swz8Xw_PU-8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import json\n",
        "\n",
        "# ===== API KEYS =====\n",
        "PINECONE_API_KEY = \"*******************************************************\"\n",
        "GOOGLE_API_KEY = \"*******************************************************\"\n",
        "# Initialize Gemini\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "# Initialize Pinecone\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index_name = \"indian-tax-chatbot\"\n",
        "\n",
        "# Delete old index if exists\n",
        "if index_name in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name)\n",
        "\n",
        "# Create new index with correct dimension\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,  # Matches Gemini's embedding size\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        ")\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "print(\"✅ APIs initialized and index created\")\n",
        "# Test Gemini embeddings\n",
        "test_embed = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=\"test\",\n",
        "    task_type=\"retrieval_document\"\n",
        ")[\"embedding\"]\n",
        "\n",
        "print(f\"✅ Gemini embedding dimension: {len(test_embed)}\")  # Should show 768\n",
        "\n",
        "# Test Pinecone connection\n",
        "print(\"Pinecone index stats:\", index.describe_index_stats())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "bV3zqRjxWLrq",
        "outputId": "da541e28-b7dc-4174-e970-0bccdc8b6a5d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ APIs initialized and index created\n",
            "✅ Gemini embedding dimension: 768\n",
            "Pinecone index stats: {'dimension': 768,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {},\n",
            " 'total_vector_count': 0,\n",
            " 'vector_type': 'dense'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import json\n",
        "\n",
        "# ===== API KEYS =====\n",
        "PINECONE_API_KEY = \"*******************************************************\"\n",
        "GOOGLE_API_KEY = \"*******************************************************\"\n",
        "\n",
        "# Initialize Gemini\n",
        "genai.configure(api_key=GOOGLE_API_KEY)\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-latest')  # Updated model name\n",
        "\n",
        "# Initialize Pinecone (WITH CORRECT DIMENSION)\n",
        "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "index_name = \"indian-tax-chatbot\"\n",
        "\n",
        "# ==== CRITICAL CHANGE: Delete and recreate index ====\n",
        "if index_name in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name)  # Delete old 1536-dim index\n",
        "    print(f\"🗑️ Deleted old index '{index_name}'\")\n",
        "\n",
        "# Create new index with 768 dimensions\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,  # Must match Gemini's embedding-001\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        ")\n",
        "print(f\"✅ Created new index '{index_name}' with 768 dimensions\")\n",
        "\n",
        "index = pc.Index(index_name)\n",
        "# Test embedding dimension\n",
        "test_embed = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=\"test\",\n",
        "    task_type=\"retrieval_document\"\n",
        ")[\"embedding\"]\n",
        "\n",
        "print(f\"Gemini embedding dimension: {len(test_embed)}\")  # Should output 768\n",
        "print(f\"Pinecone index dimension: {index.describe_index_stats().dimension}\")  # Should match"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "Tz1zG1nOVN8J",
        "outputId": "89db0fcb-5cd7-44dd-d710-0f2b4a32a337"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🗑️ Deleted old index 'indian-tax-chatbot'\n",
            "✅ Created new index 'indian-tax-chatbot' with 768 dimensions\n",
            "Gemini embedding dimension: 768\n",
            "Pinecone index dimension: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== ENTIRE SOLUTION IN ONE CELL ======\n",
        "# Run this entire block together to avoid cell isolation issues\n",
        "\n",
        "# 1. Installations\n",
        "!pip install -q google-generativeai pinecone python-dotenv\n",
        "print(\"✅ Packages installed\")\n",
        "\n",
        "# 2. Imports\n",
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "import json\n",
        "print(\"✅ Libraries imported\")\n",
        "\n",
        "# 3. Initialize APIs\n",
        "try:\n",
        "    # Configure Gemini\n",
        "    GOOGLE_API_KEY = \"*******************************************************\"\n",
        "    genai.configure(api_key=GOOGLE_API_KEY)\n",
        "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "    # Initialize Pinecone\n",
        "    PINECONE_API_KEY = \"*******************************************************\"\n",
        "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
        "    index_name = \"indian-tax-chatbot\"\n",
        "\n",
        "    # Delete old index if exists\n",
        "    if index_name in pc.list_indexes().names():\n",
        "        pc.delete_index(index_name)\n",
        "        print(f\"🗑️ Deleted old index '{index_name}'\")\n",
        "\n",
        "    # Create new index with correct dimension\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,  # Must match Gemini's embedding-001\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "    index = pc.Index(index_name)\n",
        "    print(f\"✅ Created new index '{index_name}' with 768 dimensions\")\n",
        "\n",
        "    # Verify dimensions\n",
        "    test_embed = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=\"test\",\n",
        "        task_type=\"retrieval_document\"\n",
        "    )[\"embedding\"]\n",
        "    print(f\"🔢 Gemini embedding dimension: {len(test_embed)}\")\n",
        "    print(f\"📊 Pinecone index stats: {index.describe_index_stats()}\")\n",
        "\n",
        "    # ====== SAMPLE DATA ADDITION ======\n",
        "    tax_data = [\n",
        "        {\n",
        "            \"id\": \"sec80c\",\n",
        "            \"text\": \"Section 80C allows ₹1.5L deduction for investments...\",\n",
        "            \"metadata\": {\"section\": \"80C\", \"max_amount\": 150000}\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"sec80d\",\n",
        "            \"text\": \"Section 80D provides health insurance deductions...\",\n",
        "            \"metadata\": {\"section\": \"80D\", \"max_amount\": 50000}\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    # Add to Pinecone\n",
        "    for item in tax_data:\n",
        "        embedding = genai.embed_content(\n",
        "            model=\"models/embedding-001\",\n",
        "            content=item[\"text\"],\n",
        "            task_type=\"retrieval_document\"\n",
        "        )[\"embedding\"]\n",
        "\n",
        "        index.upsert(vectors=[{\n",
        "            \"id\": item[\"id\"],\n",
        "            \"values\": embedding,\n",
        "            \"metadata\": item[\"metadata\"]\n",
        "        }])\n",
        "\n",
        "    print(f\"\\n📦 Added {len(tax_data)} tax provisions\")\n",
        "    print(\"Updated index stats:\", index.describe_index_stats())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error: {str(e)}\")\n",
        "    print(\"Troubleshooting:\")\n",
        "    print(\"1. Restart runtime (Runtime → Restart runtime)\")\n",
        "    print(\"2. Verify API keys are valid\")\n",
        "    print(\"3. Check API enablement at:\")\n",
        "    print(\"   - https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com\")\n",
        "  # ====== VECTOR UPLOAD FIX ======\n",
        "print(\"\\n🔄 Uploading vectors to Pinecone...\")\n",
        "\n",
        "success_count = 0\n",
        "for item in tax_data:\n",
        "    try:\n",
        "        # Generate embedding\n",
        "        embedding = genai.embed_content(\n",
        "            model=\"models/embedding-001\",\n",
        "            content=item[\"text\"],\n",
        "            task_type=\"retrieval_document\"\n",
        "        )[\"embedding\"]\n",
        "\n",
        "        # Debug: Print embedding dimensions\n",
        "        print(f\"Embedding for {item['id']} length: {len(embedding)}\")\n",
        "\n",
        "        # Upsert to Pinecone with timeout\n",
        "        upsert_response = index.upsert(\n",
        "            vectors=[{\n",
        "                \"id\": item[\"id\"],\n",
        "                \"values\": embedding,\n",
        "                \"metadata\": item[\"metadata\"]\n",
        "            }],\n",
        "            timeout=30  # Increased timeout\n",
        "        )\n",
        "\n",
        "        # Verify upsert\n",
        "        if upsert_response.upserted_count == 1:\n",
        "            success_count += 1\n",
        "            print(f\"✔ {item['id']} added successfully\")\n",
        "        else:\n",
        "            print(f\"⚠️ Failed to add {item['id']}: {upsert_response}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error adding {item['id']}: {str(e)}\")\n",
        "\n",
        "# Final verification\n",
        "print(f\"\\n🔍 Final verification...\")\n",
        "stats = index.describe_index_stats()\n",
        "print(\"Namespace counts:\", stats['namespaces'])\n",
        "print(\"Total vectors:\", stats['total_vector_count'])\n",
        "\n",
        "if success_count == len(tax_data):\n",
        "    print(\"\\n🎉 All vectors added successfully!\")\n",
        "else:\n",
        "    print(f\"\\n⚠️ Only {success_count}/{len(tax_data)} vectors added\")\n",
        "print(index.fetch(ids=[\"sec80c\"], namespace=\"tax_data\"))\n",
        "print(f\"https://app.pinecone.io/organizations/-/projects/{pc.whoami().project_name}/indexes/{index_name}/browser\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        },
        "id": "5wU_cVUwX6gJ",
        "outputId": "344eabdb-1cb3-42fa-e250-3444bc6d29ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Packages installed\n",
            "✅ Libraries imported\n",
            "🗑️ Deleted old index 'indian-tax-chatbot'\n",
            "✅ Created new index 'indian-tax-chatbot' with 768 dimensions\n",
            "🔢 Gemini embedding dimension: 768\n",
            "📊 Pinecone index stats: {'dimension': 768,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {},\n",
            " 'total_vector_count': 0,\n",
            " 'vector_type': 'dense'}\n",
            "\n",
            "📦 Added 2 tax provisions\n",
            "Updated index stats: {'dimension': 768,\n",
            " 'index_fullness': 0.0,\n",
            " 'metric': 'cosine',\n",
            " 'namespaces': {},\n",
            " 'total_vector_count': 0,\n",
            " 'vector_type': 'dense'}\n",
            "\n",
            "🔄 Uploading vectors to Pinecone...\n",
            "Embedding for sec80c length: 768\n",
            "✔ sec80c added successfully\n",
            "Embedding for sec80d length: 768\n",
            "✔ sec80d added successfully\n",
            "\n",
            "🔍 Final verification...\n",
            "Namespace counts: {}\n",
            "Total vectors: 0\n",
            "\n",
            "🎉 All vectors added successfully!\n",
            "FetchResponse(namespace='tax_data', vectors={}, usage=None)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'Pinecone' object has no attribute 'whoami'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-16bbe2a72906>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\n⚠️ Only {success_count}/{len(tax_data)} vectors added\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"sec80c\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tax_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"https://app.pinecone.io/organizations/-/projects/{pc.whoami().project_name}/indexes/{index_name}/browser\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Pinecone' object has no attribute 'whoami'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Clean install packages\n",
        "!pip uninstall -y pinecone-client pinecone > /dev/null 2>&1\n",
        "!pip install -q google-generativeai pinecone python-dotenv\n",
        "\n",
        "# 2. RESTART RUNTIME NOW (Runtime → Restart runtime)\n",
        "#    - This is CRUCIAL after reinstalling packages\n",
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "\n",
        "# Initialize APIs\n",
        "genai.configure(api_key=\"*******************************************************\")\n",
        "pc = Pinecone(api_key=\"*******************************************************\")\n",
        "\n",
        "# Delete old index if exists\n",
        "index_name = \"indian-tax-chatbot\"\n",
        "if index_name in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name)\n",
        "    print(f\"🗑️ Deleted old index\")\n",
        "\n",
        "# Create new index (768 dimensions)\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        ")\n",
        "index = pc.Index(index_name)\n",
        "print(f\"✅ Created index with 768 dimensions\")\n",
        "tax_data = [\n",
        "    {\"id\": \"sec80c\", \"text\": \"Section 80C allows ₹1.5L deduction...\", \"metadata\": {...}},\n",
        "    {\"id\": \"sec80d\", \"text\": \"Section 80D provides health insurance...\", \"metadata\": {...}}\n",
        "]\n",
        "\n",
        "# 1. Verify embeddings first\n",
        "test_embed = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=\"test\",\n",
        "    task_type=\"retrieval_document\"\n",
        ")[\"embedding\"]\n",
        "print(f\"🔢 Embedding dimension: {len(test_embed)}\")  # Must show 768\n",
        "\n",
        "# 2. Upload with verification\n",
        "for item in tax_data:\n",
        "    embedding = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=item[\"text\"],\n",
        "        task_type=\"retrieval_document\"\n",
        "    )[\"embedding\"]\n",
        "\n",
        "    response = index.upsert(\n",
        "        vectors=[{\n",
        "            \"id\": item[\"id\"],\n",
        "            \"values\": embedding,\n",
        "            \"metadata\": item[\"metadata\"]\n",
        "        }],\n",
        "        namespace=\"tax_data\"  # Explicit namespace\n",
        "    )\n",
        "    print(f\"Added {item['id']} - Response: {response}\")\n",
        "\n",
        "# 3. Final verification\n",
        "print(\"\\n🔍 Final Stats:\")\n",
        "print(index.describe_index_stats())\n",
        "print(\"\\nSample fetch:\")\n",
        "print(index.fetch(ids=[\"sec80c\"], namespace=\"tax_data\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "cqXcwlUDY-nf",
        "outputId": "e90e0aaf-cea9-4619-ddce-0bdb97696187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🗑️ Deleted old index\n",
            "✅ Created index with 768 dimensions\n",
            "🔢 Embedding dimension: 768\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "MetadataDictionaryExpectedError",
          "evalue": "Column `metadata` is expected to be a dictionary, found <class 'set'>",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMetadataDictionaryExpectedError\u001b[0m           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8cdc84a62c3e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m     )[\"embedding\"]\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     response = index.upsert(\n\u001b[0m\u001b[1;32m     51\u001b[0m         vectors=[{\n\u001b[1;32m     52\u001b[0m             \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pinecone/utils/error_handling.py\u001b[0m in \u001b[0;36minner_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minner_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProtocolError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pinecone/data/index.py\u001b[0m in \u001b[0;36mupsert\u001b[0;34m(self, vectors, namespace, batch_size, show_progress, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_upsert_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pinecone/data/index.py\u001b[0m in \u001b[0;36m_upsert_batch\u001b[0;34m(self, vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     ) -> UpsertResponse:\n\u001b[1;32m    167\u001b[0m         return self._vector_api.upsert_vectors(\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0mIndexRequestFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsert_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_openapi_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pinecone/data/request_factory.py\u001b[0m in \u001b[0;36mupsert_request\u001b[0;34m(vectors, namespace, _check_type, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         return UpsertRequest(\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mvectors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_builder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0;34m**\u001b[0m\u001b[0margs_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0m_check_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pinecone/data/request_factory.py\u001b[0m in \u001b[0;36mvec_builder\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvec_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mVectorFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_check_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         return UpsertRequest(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pinecone/data/vector_factory.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(item, check_type)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mVectorFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tuple_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mVectorFactory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dict_to_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Invalid vector value passed: cannot interpret type {type(item)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pinecone/data/vector_factory.py\u001b[0m in \u001b[0;36m_dict_to_vector\u001b[0;34m(item, check_type)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mmetadata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mitem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mMetadataDictionaryExpectedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMetadataDictionaryExpectedError\u001b[0m: Column `metadata` is expected to be a dictionary, found <class 'set'>"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggyaZ98m5lYu",
        "outputId": "b2525693-f16c-4ed3-c2c7-78a862d94fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Setup complete! Ready to use:\n",
            "- genai model: genai.GenerativeModel(\n",
            "    model_name='models/gemini-1.5-pro-latest',\n",
            "    generation_config={},\n",
            "    safety_settings={},\n",
            "    tools=None,\n",
            "    system_instruction=None,\n",
            "    cached_content=None\n",
            ")\n",
            "- pinecone index: <pinecone.data.index.Index object at 0x7ecbd426a0d0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== FINAL WORKING SOLUTION ======\n",
        "# Run in a FRESH runtime (Runtime → Restart runtime first)\n",
        "\n",
        "# 1. Clean installation\n",
        "!pip uninstall -y pinecone-client pinecone > /dev/null 2>&1\n",
        "!pip install -q google-generativeai pinecone python-dotenv\n",
        "\n",
        "# 2. Imports\n",
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from time import sleep\n",
        "\n",
        "# 3. Initialize APIs\n",
        "try:\n",
        "    print(\"🔌 Initializing APIs...\")\n",
        "\n",
        "    # Configure Gemini\n",
        "    genai.configure(api_key=\"*******************************************************\")\n",
        "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "    # Initialize Pinecone\n",
        "    pc = Pinecone(api_key=\"*******************************************************\")\n",
        "    index_name = \"indian-tax-chatbot\"\n",
        "\n",
        "    # Delete old index if exists\n",
        "    if index_name in pc.list_indexes().names():\n",
        "        pc.delete_index(index_name)\n",
        "        print(\"🗑️ Deleted old index\")\n",
        "        sleep(10)  # Wait for deletion to complete\n",
        "\n",
        "    # Create new index\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "    print(\"✅ Created index (768 dim)\")\n",
        "    index = pc.Index(index_name)\n",
        "    sleep(15)  # Critical - wait for index to be ready\n",
        "\n",
        "    # ====== DATA UPLOAD ======\n",
        "    tax_data = [\n",
        "        {\n",
        "            \"id\": \"sec80c\",\n",
        "            \"text\": \"Section 80C allows ₹1.5L deduction for investments in PPF, EPF, ELSS, etc.\",\n",
        "            \"metadata\": {\"section\": \"80C\", \"max_amount\": 150000}  # Must be dict\n",
        "        },\n",
        "        {\n",
        "            \"id\": \"sec80d\",\n",
        "            \"text\": \"Section 80D provides health insurance deductions up to ₹50,000 for individuals.\",\n",
        "            \"metadata\": {\"section\": \"80D\", \"max_amount\": 50000}  # Must be dict\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    print(\"\\n⬆️ Uploading vectors...\")\n",
        "    for item in tax_data:\n",
        "        # Generate embedding\n",
        "        embedding = genai.embed_content(\n",
        "            model=\"models/embedding-001\",\n",
        "            content=item[\"text\"],\n",
        "            task_type=\"retrieval_document\"\n",
        "        )[\"embedding\"]\n",
        "\n",
        "        # Upsert with verification\n",
        "        response = index.upsert(\n",
        "            vectors=[{\n",
        "                \"id\": item[\"id\"],\n",
        "                \"values\": embedding,\n",
        "                \"metadata\": item[\"metadata\"]  # Proper dictionary format\n",
        "            }],\n",
        "            namespace=\"tax_laws\"  # Specific namespace\n",
        "        )\n",
        "        print(f\"• {item['id']}: {'✅' if response.upserted_count == 1 else '❌'}\")\n",
        "\n",
        "    # ====== FINAL VERIFICATION ======\n",
        "    print(\"\\n🔎 Verifying upload...\")\n",
        "    sleep(10)  # Allow time for indexing\n",
        "\n",
        "    # PROPER way to handle FetchResponse in new Pinecone client\n",
        "    fetched = index.fetch(ids=[\"sec80c\", \"sec80d\"], namespace=\"tax_laws\")\n",
        "    print(f\"Fetched vectors: {len(fetched.vectors)}\")  # Using .vectors not ['vectors']\n",
        "\n",
        "    # Index stats\n",
        "    stats = index.describe_index_stats()\n",
        "    print(f\"\\n📊 Index stats:\")\n",
        "    print(f\"Total vectors: {stats.total_vector_count}\")  # Using dot notation\n",
        "    print(f\"Namespaces: {stats.namespaces}\")\n",
        "\n",
        "    # Console link (using your project name from screenshot)\n",
        "    print(\"\\n🌐 Check console:\")\n",
        "    print(f\"https://app.pinecone.io/project/ai-agents/index/indian-tax-chatbot/browser\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Error: {str(e)}\")\n",
        "    print(\"Immediate actions:\")\n",
        "    print(\"1. RESTART RUNTIME (Runtime → Restart runtime)\")\n",
        "    print(\"2. Verify metadata is dictionary format\")\n",
        "# Sample query code\n",
        "query_text = \"What is the deduction limit for health insurance?\"\n",
        "query_embedding = genai.embed_content(\n",
        "    model=\"models/embedding-001\",\n",
        "    content=query_text,\n",
        "    task_type=\"retrieval_query\"\n",
        ")[\"embedding\"]\n",
        "\n",
        "results = index.query(\n",
        "    vector=query_embedding,\n",
        "    top_k=2,\n",
        "    namespace=\"tax_laws\",\n",
        "    include_metadata=True\n",
        ")\n",
        "\n",
        "for match in results.matches:\n",
        "    print(f\"Section {match.metadata['section']}: {match.score:.2f}\")\n",
        "    print(f\"Details: {match.metadata}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "aIaRouPXadl9",
        "outputId": "7312cc38-125b-4c4a-9ec8-e2c19e7f07de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔌 Initializing APIs...\n",
            "🗑️ Deleted old index\n",
            "✅ Created index (768 dim)\n",
            "\n",
            "⬆️ Uploading vectors...\n",
            "• sec80c: ✅\n",
            "• sec80d: ✅\n",
            "\n",
            "🔎 Verifying upload...\n",
            "Fetched vectors: 2\n",
            "\n",
            "📊 Index stats:\n",
            "Total vectors: 2\n",
            "Namespaces: {'tax_laws': {'vector_count': 2}}\n",
            "\n",
            "🌐 Check console:\n",
            "https://app.pinecone.io/project/ai-agents/index/indian-tax-chatbot/browser\n",
            "Section 80D: 0.74\n",
            "Details: {'max_amount': 50000.0, 'section': '80D'}\n",
            "Section 80C: 0.64\n",
            "Details: {'max_amount': 150000.0, 'section': '80C'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== UPDATED INITIALIZATION CELL ======\n",
        "# 1. Clean install\n",
        "!pip uninstall -y pinecone-client pinecone > /dev/null 2>&1\n",
        "!pip install -q google-generativeai pinecone python-dotenv requests\n",
        "\n",
        "# 2. Imports\n",
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# 3. Initialize APIs\n",
        "genai.configure(api_key=\"*******************************************************\")  # Your key\n",
        "model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "pc = Pinecone(api_key=\"*******************************************************\")  # Your key\n",
        "index_name = \"indian-tax-chatbot\"\n",
        "\n",
        "# 4. Setup Pinecone Index\n",
        "if index_name in pc.list_indexes().names():\n",
        "    pc.delete_index(index_name)\n",
        "    time.sleep(10)\n",
        "\n",
        "pc.create_index(\n",
        "    name=index_name,\n",
        "    dimension=768,\n",
        "    metric=\"cosine\",\n",
        "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        ")\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(15)\n",
        "\n",
        "print(\"✅ Setup complete! Ready to use:\")\n",
        "print(\"- genai model:\", model)\n",
        "print(\"- pinecone index:\", index)\n",
        "# Step 1: Create user profile structure\n",
        "def create_user_profile(user_id):\n",
        "    return {\n",
        "        \"user_id\": user_id,  # Unique identifier (hash of email/phone)\n",
        "        \"income_sources\": [],\n",
        "        \"investments\": {},\n",
        "        \"family_status\": \"\",\n",
        "        \"housing_loan\": False,\n",
        "        \"previous_discussions\": []  # Will store vector IDs\n",
        "    }\n",
        "\n",
        "# Step 2: Profile update function\n",
        "def update_profile(profile, new_data):\n",
        "    for key, value in new_data.items():\n",
        "        if key in profile:\n",
        "            profile[key] = value\n",
        "    return profile\n",
        "# Step 3: Modified upsert with user context\n",
        "def store_conversation(user_id, conversation_text, metadata={}):\n",
        "    embedding = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=conversation_text,\n",
        "        task_type=\"retrieval_document\"\n",
        "    )[\"embedding\"]\n",
        "\n",
        "    vector_id = f\"conv_{int(time.time())}\"\n",
        "\n",
        "    index.upsert(vectors=[{\n",
        "        \"id\": vector_id,\n",
        "        \"values\": embedding,\n",
        "        \"metadata\": {\n",
        "            \"user_id\": user_id,\n",
        "            \"timestamp\": datetime.now().isoformat(),\n",
        "            **metadata\n",
        "        }\n",
        "    }], namespace=\"user_conversations\")\n",
        "\n",
        "    return vector_id\n",
        "# Step 4: Recall previous discussions\n",
        "def get_previous_context(user_id, current_query, top_k=3):\n",
        "    # Get embedding of current query\n",
        "    query_embed = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=current_query,\n",
        "        task_type=\"retrieval_query\"\n",
        "    )[\"embedding\"]\n",
        "\n",
        "    # Query with user filter\n",
        "    results = index.query(\n",
        "        vector=query_embed,\n",
        "        top_k=top_k,\n",
        "        namespace=\"user_conversations\",\n",
        "        filter={\"user_id\": {\"$eq\": user_id}},\n",
        "        include_metadata=True\n",
        "    )\n",
        "\n",
        "    return [match.metadata for match in results.matches]\n",
        "# Step 5: Deduction analysis tool\n",
        "def analyze_deductions(user_profile):\n",
        "    applicable = []\n",
        "\n",
        "    # Check 80C eligibility\n",
        "    if any(inv in user_profile[\"investments\"] for inv in [\"PPF\", \"ELSS\", \"FD\"]):\n",
        "        applicable.append({\n",
        "            \"section\": \"80C\",\n",
        "            \"max_amount\": 150000,\n",
        "            \"description\": \"Investments in specified instruments\"\n",
        "        })\n",
        "\n",
        "    # Check 80D eligibility\n",
        "    if user_profile.get(\"health_insurance\"):\n",
        "        applicable.append({\n",
        "            \"section\": \"80D\",\n",
        "            \"max_amount\": 50000 if user_profile[\"age\"] > 60 else 25000,\n",
        "            \"description\": \"Health insurance premium\"\n",
        "        })\n",
        "\n",
        "    return applicable\n",
        "# Step 6: Real-time tax updates\n",
        "def get_tax_updates():\n",
        "    url = \"https://newsapi.org/v2/everything?q=india+tax+law&sortBy=publishedAt&apiKey=YOUR_KEY\"\n",
        "    response = requests.get(url)\n",
        "    articles = response.json().get(\"articles\", [])\n",
        "\n",
        "    # Process and store relevant updates\n",
        "    for article in articles[:5]:  # Limit to 5 most recent\n",
        "        store_conversation(\n",
        "            user_id=\"system\",\n",
        "            conversation_text=article[\"title\"] + \"\\n\" + article[\"description\"],\n",
        "            metadata={\n",
        "                \"source\": \"NewsAPI\",\n",
        "                \"published_at\": article[\"publishedAt\"],\n",
        "                \"type\": \"tax_update\"\n",
        "            }\n",
        "        )\n",
        "# Step 7: Main conversation processor\n",
        "def handle_query(user_id, query):\n",
        "    # Step 1: Get user profile (from DB in production)\n",
        "    profile = get_user_profile(user_id)\n",
        "\n",
        "    # Step 2: Recall relevant context\n",
        "    context = get_previous_context(user_id, query)\n",
        "\n",
        "    # Step 3: Get latest updates\n",
        "    tax_updates = get_tax_updates()\n",
        "\n",
        "    # Step 4: Generate response\n",
        "    prompt = f\"\"\"\n",
        "    User Profile: {profile}\n",
        "    Previous Discussions: {context}\n",
        "    Latest Updates: {tax_updates}\n",
        "\n",
        "    New Query: {query}\n",
        "    \"\"\"\n",
        "\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    # Step 5: Store this interaction\n",
        "    store_conversation(user_id, f\"Q: {query}\\nA: {response.text}\")\n",
        "\n",
        "    return response.text\n",
        "# Silent setup - no print needed\n",
        "user_profiles = {}\n",
        "\n",
        "def get_user_profile(user_id):\n",
        "    if user_id not in user_profiles:\n",
        "        user_profiles[user_id] = {\n",
        "            \"user_id\": user_id,\n",
        "            \"income_sources\": [],\n",
        "            \"investments\": {},\n",
        "            \"family_status\": \"\",\n",
        "            \"previous_discussions\": []\n",
        "        }\n",
        "    return user_profiles[user_id]\n",
        "def silent_upsert(user_id, text, metadata={}):\n",
        "    embedding = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=text,\n",
        "        task_type=\"retrieval_document\"\n",
        "    )[\"embedding\"]\n",
        "\n",
        "    vector_id = f\"mem_{user_id}_{int(time.time())}\"\n",
        "    index.upsert(\n",
        "        vectors=[{\n",
        "            \"id\": vector_id,\n",
        "            \"values\": embedding,\n",
        "            \"metadata\": {\"user_id\": user_id, **metadata}\n",
        "        }],\n",
        "        namespace=\"tax_memory\"\n",
        "    )\n",
        "    return vector_id  # No print\n",
        "def get_context(user_id, query, top_k=2):\n",
        "    query_embed = genai.embed_content(\n",
        "        model=\"models/embedding-001\",\n",
        "        content=query,\n",
        "        task_type=\"retrieval_query\"\n",
        "    )[\"embedding\"]\n",
        "\n",
        "    return index.query(\n",
        "        vector=query_embed,\n",
        "        top_k=top_k,\n",
        "        filter={\"user_id\": {\"$eq\": user_id}},\n",
        "        namespace=\"tax_memory\",\n",
        "        include_metadata=True\n",
        "    )\n",
        "# Tool 1: Deduction Calculator\n",
        "def calculate_deductions(profile):\n",
        "    deductions = []\n",
        "    if profile[\"investments\"].get(\"80C\"):\n",
        "        deductions.append((\"80C\", min(150000, profile[\"investments\"][\"80C\"])))\n",
        "    return deductions\n",
        "\n",
        "# Tool 2: Update Checker\n",
        "def check_for_updates():\n",
        "    # Placeholder for API call\n",
        "    return [{\"section\": \"80C\", \"change\": \"New PPF limits\"}]\n",
        "# ====== LLM INTEGRATION (NEW CELL) ======\n",
        "# 1. First-time setup (run only once)\n",
        "!pip install -q google-generativeai\n",
        "import google.generativeai as genai\n",
        "from datetime import datetime\n",
        "\n",
        "# 2. Initialize Gemini Model\n",
        "genai.configure(api_key=\"*******************************************************\")\n",
        "tax_agent = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "# 3. Fixed Handler Function\n",
        "def tax_chatbot(user_id, query):\n",
        "    \"\"\"Handles complete query processing\"\"\"\n",
        "    try:\n",
        "        # Get user context\n",
        "        profile = get_user_profile(user_id)\n",
        "        context = get_previous_context(user_id, query)\n",
        "        deductions = analyze_deductions(profile)\n",
        "\n",
        "        # Generate response\n",
        "        response = tax_agent.generate_content(\n",
        "            f\"\"\"**Act as Indian Tax Expert**\\n\n",
        "            User Profile:\\n{profile}\\n\n",
        "            Past Discussions:\\n{context}\\n\n",
        "            Eligible Deductions:\\n{deductions}\\n\\n\n",
        "            Query: \"{query}\"\\n\n",
        "            Give detailed, personalized answer with section references.\n",
        "            \"\"\"\n",
        "        )\n",
        "\n",
        "        # Store conversation\n",
        "        store_conversation(\n",
        "            user_id=user_id,\n",
        "            conversation_text=f\"Q: {query}\\nA: {response.text}\",\n",
        "            metadata={\"type\": \"tax_advice\"}\n",
        "        )\n",
        "\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Error: {str(e)}\")\n",
        "        return \"Unable to process request. Please try again.\"\n",
        "\n",
        "# 4. Test Function\n",
        "def test_flow():\n",
        "    # Setup test user\n",
        "    user_id = \"test_user_001\"\n",
        "    profile = {\n",
        "        \"investments\": {\"PPF\": 150000, \"ELSS\": 50000},\n",
        "        \"health_insurance\": True,\n",
        "        \"age\": 45\n",
        "    }\n",
        "    update_profile(get_user_profile(user_id), profile)\n",
        "\n",
        "    # Test query\n",
        "    query = \"How much tax can I save under 80C and 80D?\"\n",
        "    return tax_chatbot(user_id, query)\n",
        "\n",
        "# 5. Execute Test\n",
        "test_response = test_flow()\n",
        "print(\"💬 Tax Bot Response:\")\n",
        "print(test_response)\n",
        "# Add to your profile structure\n",
        "def add_health_insurance(user_id, details):\n",
        "    profile = get_user_profile(user_id)\n",
        "    profile[\"health_insurance\"] = {\n",
        "        \"self_covered\": details.get(\"self\", False),\n",
        "        \"parents_covered\": details.get(\"parents\", False),\n",
        "        \"premium_amount\": details.get(\"amount\", 0)\n",
        "    }\n",
        "    return profile\n",
        "def get_budget_updates():\n",
        "    \"\"\"Fetch latest budget announcements\"\"\"\n",
        "    import requests\n",
        "    url = \"https://newsapi.org/v2/everything?q=india+union+budget+2025&apiKey=YOUR_KEY\"\n",
        "    response = requests.get(url)\n",
        "    return [article[\"title\"] for article in response.json().get(\"articles\",[])[:3]]\n",
        "def get_chat_history(user_id):\n",
        "    return index.query(\n",
        "        vector=[0]*768,  # Dummy vector\n",
        "        filter={\"user_id\": {\"$eq\": user_id}},\n",
        "        namespace=\"tax_conversations\",\n",
        "        include_metadata=True,\n",
        "        top_k=5\n",
        "    )\n",
        "def get_latest_tax_updates():\n",
        "    \"\"\"Fetch real-time tax law changes using Serper API\"\"\"\n",
        "    import requests\n",
        "    import json\n",
        "\n",
        "    url = \"https://google.serper.dev/search\"\n",
        "    payload = json.dumps({\n",
        "        \"q\": \"site:incometaxindia.gov.in latest notification after:2025-03-01\",\n",
        "        \"gl\": \"in\"\n",
        "    })\n",
        "    headers = {\n",
        "        'X-API-KEY': '*******************************************************',  # Get free tier key at serper.dev\n",
        "        'Content-Type': 'application/json'\n",
        "    }\n",
        "\n",
        "    response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
        "    updates = [item[\"title\"] for item in response.json().get(\"organic\", [])[:3]]\n",
        "    return {\"source\": \"IncomeTaxIndia.gov.in\", \"updates\": updates}\n",
        "def handle_query(user_id, query):\n",
        "    try:\n",
        "        profile = get_user_profile(user_id)\n",
        "        context = get_previous_context(user_id, query)\n",
        "        updates = get_tax_updates()  # Using our new tool\n",
        "\n",
        "        prompt = f\"\"\"**Act as Tax Expert with Latest Info**\n",
        "\n",
        "        Latest Updates: {updates}\n",
        "\n",
        "        User Profile: {profile}\n",
        "\n",
        "        Conversation History: {context}\n",
        "\n",
        "        Question: {query}\n",
        "\n",
        "        Give specific advice referencing:\n",
        "        1. Relevant sections from user profile\n",
        "        2. Any applicable recent changes\n",
        "        3. Precise calculation if needed\"\"\"\n",
        "\n",
        "        response = model.generate_content(prompt)\n",
        "\n",
        "        # Store interaction\n",
        "        store_conversation(\n",
        "            user_id=user_id,\n",
        "            conversation_text=f\"Q: {query}\\nA: {response.text}\",\n",
        "            metadata={\n",
        "                \"type\": \"tax_advice\",\n",
        "                \"sources\": [updates.get(\"source\")]\n",
        "            }\n",
        "        )\n",
        "\n",
        "        return response.text\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Tax query failed: {str(e)}\"\n",
        "        print(error_msg)\n",
        "        return error_msg\n",
        "# Test the new functionality\n",
        "print(\"📢 Latest Updates:\", get_latest_tax_updates())\n",
        "test_response = tax_chatbot(\"test_user_001\",\n",
        "    \"How do the recent notifications affect my 80D claims?\")\n",
        "print(test_response)\n",
        "try:\n",
        "    updates = get_latest_tax_updates()\n",
        "except Exception as e:\n",
        "    updates = {\"error\": str(e)}\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "update_cache = {\"last_fetched\": None, \"data\": None}\n",
        "\n",
        "def get_cached_updates():\n",
        "    if update_cache[\"last_fetched\"] and \\\n",
        "       (datetime.now() - update_cache[\"last_fetched\"]) < timedelta(hours=1):\n",
        "        return update_cache[\"data\"]\n",
        "    update_cache[\"data\"] = get_latest_tax_updates()\n",
        "    update_cache[\"last_fetched\"] = datetime.now()\n",
        "    return update_cache[\"data\"]\n",
        "# ====== REAL-TIME TAX UPDATES TOOL ======\n",
        "update_cache = {\n",
        "    \"last_fetched\": None,\n",
        "    \"data\": None,\n",
        "    \"cache_duration\": timedelta(hours=1)  # Refresh every hour\n",
        "}\n",
        "\n",
        "def get_tax_updates():\n",
        "    \"\"\"Get latest tax notifications with caching and error handling\"\"\"\n",
        "    try:\n",
        "        # Return cached data if still valid\n",
        "        if update_cache[\"last_fetched\"] and \\\n",
        "           (datetime.now() - update_cache[\"last_fetched\"]) < update_cache[\"cache_duration\"]:\n",
        "            return update_cache[\"data\"]\n",
        "\n",
        "        # Fetch fresh data\n",
        "        url = \"https://google.serper.dev/search\"\n",
        "        payload = json.dumps({\n",
        "            \"q\": \"site:incometaxindia.gov.in notification after:{date}\".format(\n",
        "                date=(datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")),\n",
        "            \"gl\": \"in\",\n",
        "            \"num\": 5\n",
        "        })\n",
        "        headers = {\n",
        "            'X-API-KEY': '*******************************************************',\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "\n",
        "        response = requests.post(url, headers=headers, data=payload, timeout=10)\n",
        "        response.raise_for_status()\n",
        "\n",
        "        # Process and cache results\n",
        "        updates = [{\n",
        "            \"title\": item[\"title\"],\n",
        "            \"link\": item[\"link\"],\n",
        "            \"snippet\": item.get(\"snippet\", \"\")\n",
        "        } for item in response.json().get(\"organic\", [])[:3]]\n",
        "\n",
        "        update_cache[\"data\"] = {\n",
        "            \"source\": \"IncomeTaxIndia.gov.in\",\n",
        "            \"last_checked\": datetime.now().isoformat(),\n",
        "            \"updates\": updates\n",
        "        }\n",
        "        update_cache[\"last_fetched\"] = datetime.now()\n",
        "\n",
        "        return update_cache[\"data\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"⚠️ Update fetch failed: {str(e)}\")\n",
        "        return {\n",
        "            \"error\": \"Could not fetch updates\",\n",
        "            \"cached_data\": update_cache[\"data\"]\n",
        "        }\n",
        "# Safe test without exposing API calls\n",
        "test_query = \"How do recent notifications affect NRI taxation?\"\n",
        "test_response = handle_query(\"test_user_007\", test_query)\n",
        "\n",
        "print(\"🔍 Test Results:\")\n",
        "print(\"First 200 chars:\", test_response[:200] + \"...\")\n",
        "print(\"\\nUpdate Cache Status:\", bool(update_cache[\"data\"]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "u46GYKZ65Y1O",
        "outputId": "318392e0-1466-4094-adaf-800184ad2450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Setup complete! Ready to use:\n",
            "- genai model: genai.GenerativeModel(\n",
            "    model_name='models/gemini-1.5-pro-latest',\n",
            "    generation_config={},\n",
            "    safety_settings={},\n",
            "    tools=None,\n",
            "    system_instruction=None,\n",
            "    cached_content=None\n",
            ")\n",
            "- pinecone index: <pinecone.data.index.Index object at 0x7fdb7ddf60d0>\n",
            "💬 Tax Bot Response:\n",
            "Hello,\n",
            "\n",
            "Based on the information you've provided, let's explore your potential tax savings under sections 80C and 80D of the Income Tax Act, 1961.\n",
            "\n",
            "**Section 80C: Deductions for Investments**\n",
            "\n",
            "Section 80C allows for deductions up to ₹150,000 per year for investments in specified instruments. You've mentioned investments in PPF (Public Provident Fund) and ELSS (Equity Linked Savings Scheme).\n",
            "\n",
            "* **PPF:** Your contribution of ₹150,000 to PPF is eligible for deduction under 80C.\n",
            "* **ELSS:** Your investment of ₹50,000 in ELSS is also eligible for deduction under 80C.\n",
            "\n",
            "Since the combined investment in PPF and ELSS is ₹200,000, and the maximum deduction limit under 80C is ₹150,000, you can claim the full ₹150,000 as a deduction.  This will reduce your taxable income by ₹150,000.  The remaining ₹50,000 investment in ELSS (above the 80C limit) cannot be claimed under this section.\n",
            "\n",
            "**Section 80D: Deductions for Health Insurance Premiums**\n",
            "\n",
            "You haven't provided any information about health insurance premiums paid.  Therefore, I cannot calculate potential tax savings under Section 80D.  Please provide information about premiums paid for yourself, your spouse, dependent children, and parents to determine the eligible deduction.  The deduction limits vary based on the age of the insured individuals.\n",
            "\n",
            "**Summary of Tax Savings (Based on available information):**\n",
            "\n",
            "* **80C:** ₹150,000\n",
            "* **80D:**  Cannot be determined without further information.\n",
            "\n",
            "**To maximize your tax benefits, consider the following:**\n",
            "\n",
            "* **Providing Health Insurance details:**  Share details of your health insurance premiums paid to calculate the 80D deduction.\n",
            "* **Other 80C Investments:** Although you have maxed out your 80C limit with PPF and ELSS, for future reference, be aware that other eligible investments under 80C include life insurance premiums, tuition fees for children's education, principal repayment on a home loan, National Savings Certificates (NSC), and more.\n",
            "\n",
            "I hope this helps.  Please provide the missing health insurance information so I can give you a complete picture of your potential tax savings.  I am here to assist further if you have any more questions.\n",
            "\n",
            "📢 Latest Updates: {'source': 'IncomeTaxIndia.gov.in', 'updates': ['Circulars & Notifications', 'Tax Laws & Rules > Circulars & Notifications > Notifications', 'Tax Laws & Rules > Circulars & Notifications > Circulars']}\n",
            "As an Indian Tax Expert, I can address your query about the impact of recent notifications on your 80D claims. However, your provided user profile lacks crucial information about your health insurance premiums paid.  80D pertains to deductions on health insurance premiums. Without knowing those details, I can only offer a general explanation of 80D and how recent changes *might* affect you.  Please provide details about the premiums you pay for yourself, your spouse, your children, and your parents (including their age) for a personalized assessment.\n",
            "\n",
            "**General Explanation of Section 80D Deduction:**\n",
            "\n",
            "Section 80D of the Income Tax Act allows deductions for premiums paid towards health insurance policies for yourself, your spouse, dependent children, and parents.  The deductions are subject to certain limits, which can change based on government notifications.\n",
            "\n",
            "**Potential Impact of Recent Notifications (General):**\n",
            "\n",
            "While you haven't specified which notifications you're referring to, some recent changes that *could* affect your 80D claims include:\n",
            "\n",
            "* **No major changes in the basic structure of 80D:** In recent years, there haven't been sweeping changes to the basic framework of 80D.  The limits are typically adjusted minimally, if at all, in the annual budget.\n",
            "* **Clarifications and updates related to specific situations:** There might have been clarifications issued by the CBDT (Central Board of Direct Taxes) regarding eligibility or specific scenarios relating to 80D. These clarifications don't usually change the core deduction rules but offer interpretations for specific situations.  For example, clarifications may have been issued on the treatment of premiums paid for specific diseases or through specific modes of payment.\n",
            "* **Impact of COVID-19 related expenses:** In the past, there were specific provisions introduced for COVID-19 related expenses. However, most of those specific provisions are no longer applicable for the current financial year.  It is crucial to verify the applicability of any special provisions for the current assessment year.\n",
            "\n",
            "\n",
            "**Deduction Limits (as of the knowledge cutoff date of September 2021 - Please verify with the latest Income Tax Act for current limits):**\n",
            "\n",
            "* **For Self, Spouse, and Dependent Children:**  A maximum deduction of ₹25,000 is generally allowed.  If you or your spouse is a senior citizen (60 years or older), the limit increases to ₹50,000.\n",
            "* **For Parents:** A maximum deduction of ₹25,000 is generally allowed. If your parents are senior citizens, the limit increases to ₹50,000. If both you and your parents are senior citizens, the limit for premiums paid for your parents can go up to ₹100,000.\n",
            "\n",
            "**Preventive Health Check-up:**  A further deduction of ₹5,000 is allowed for preventive health check-ups for self, spouse, dependent children, and parents. This is included within the overall limits mentioned above.\n",
            "\n",
            "**How to find the latest Notifications:**\n",
            "\n",
            "You can find the latest notifications and circulars related to income tax on the Income Tax Department's website ([www.incometaxindia.gov.in](www.incometaxindia.gov.in)) and the CBDT website.  \n",
            "\n",
            "**Next Steps:**\n",
            "\n",
            "To provide you with a truly personalized answer and assess the impact of recent notifications on *your* 80D claims, please share the following:\n",
            "\n",
            "1. Premiums paid for your health insurance.\n",
            "2. Premiums paid for your spouse's health insurance (if applicable).\n",
            "3. Premiums paid for your children's health insurance (if applicable, and their ages).\n",
            "4. Premiums paid for your parents' health insurance (if applicable, and their ages).\n",
            "5.  Any specific notifications or circulars you are concerned about.\n",
            "\n",
            "With this information, I can accurately calculate your eligible deduction under Section 80D.\n",
            "\n",
            "⚠️ Update fetch failed: name 'json' is not defined\n",
            "Tax query failed: (400)\n",
            "Reason: Bad Request\n",
            "HTTP response headers: HTTPHeaderDict({'Date': 'Tue, 22 Apr 2025 04:09:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '137', 'Connection': 'keep-alive', 'x-pinecone-request-latency-ms': '28', 'x-pinecone-request-id': '5641739938512036378', 'x-envoy-upstream-service-time': '29', 'server': 'envoy'})\n",
            "HTTP response body: {\"code\":3,\"message\":\"Metadata value must be a string, number, boolean or list of strings, got '[null]' for field 'sources'\",\"details\":[]}\n",
            "\n",
            "🔍 Test Results:\n",
            "First 200 chars: Tax query failed: (400)\n",
            "Reason: Bad Request\n",
            "HTTP response headers: HTTPHeaderDict({'Date': 'Tue, 22 Apr 2025 04:09:44 GMT', 'Content-Type': 'application/json', 'Content-Length': '137', 'Connection': '...\n",
            "\n",
            "Update Cache Status: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== COMPLETE TAX CHATBOT SOLUTION ======\n",
        "# Run in a FRESH runtime (Runtime → Restart runtime first)\n",
        "\n",
        "# 1. Installations and Imports\n",
        "!pip uninstall -y pinecone-client pinecone > /dev/null 2>&1\n",
        "!pip install -q google-generativeai pinecone python-dotenv requests fastapi uvicorn python-multipart prometheus_client pdfminer.six\n",
        "\n",
        "import google.generativeai as genai\n",
        "from pinecone import Pinecone, ServerlessSpec\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "from cryptography.fernet import Fernet\n",
        "import base64\n",
        "import os\n",
        "from cryptography.hazmat.primitives import hashes\n",
        "from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC\n",
        "from collections import defaultdict\n",
        "from functools import lru_cache\n",
        "from fastapi import FastAPI, Depends, HTTPException\n",
        "import uvicorn\n",
        "from fastapi.security import OAuth2PasswordBearer\n",
        "from prometheus_client import start_http_server, Counter\n",
        "import sqlite3\n",
        "from dotenv import load_dotenv\n",
        "from pdfminer.high_level import extract_text\n",
        "import asyncio\n",
        "\n",
        "# 2. Initialize APIs\n",
        "try:\n",
        "    print(\"🔌 Initializing APIs...\")\n",
        "    load_dotenv()\n",
        "\n",
        "    # Configure Gemini\n",
        "    genai.configure(api_key=os.getenv(\"GEMINI_API_KEY\", \"*******************************************************\"))\n",
        "    model = genai.GenerativeModel('gemini-1.5-pro-latest')\n",
        "\n",
        "    # Initialize Pinecone\n",
        "    pc = Pinecone(api_key=os.getenv(\"PINECONE_API_KEY\", \"*******************************************************\"))\n",
        "    index_name = \"indian-tax-chatbot\"\n",
        "\n",
        "    # Setup Pinecone Index\n",
        "    if index_name in pc.list_indexes().names():\n",
        "        pc.delete_index(index_name)\n",
        "        print(\"🗑️ Deleted old index\")\n",
        "        time.sleep(10)\n",
        "\n",
        "    pc.create_index(\n",
        "        name=index_name,\n",
        "        dimension=768,\n",
        "        metric=\"cosine\",\n",
        "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
        "    )\n",
        "    index = pc.Index(index_name)\n",
        "    time.sleep(15)\n",
        "    print(\"✅ Created index (768 dim)\")\n",
        "\n",
        "    # ====== CORE FUNCTIONS ======\n",
        "    user_profiles = {}  # In-memory DB\n",
        "    active_sessions = {}  # For session management\n",
        "    METRICS = {\n",
        "        'queries_processed': defaultdict(int),\n",
        "        'response_time': defaultdict(float),\n",
        "        'errors': defaultdict(int)\n",
        "    }\n",
        "\n",
        "    def get_user_profile(user_id):\n",
        "        if user_id not in user_profiles:\n",
        "            user_profiles[user_id] = {\n",
        "                \"user_id\": user_id,\n",
        "                \"income_sources\": [],\n",
        "                \"investments\": {},\n",
        "                \"family_status\": \"\",\n",
        "                \"housing_loan\": False,\n",
        "                \"age\": None,\n",
        "                \"previous_discussions\": []\n",
        "            }\n",
        "        return user_profiles[user_id]\n",
        "\n",
        "    def update_profile(profile, new_data):\n",
        "        for key, value in new_data.items():\n",
        "            if key in profile:\n",
        "                profile[key] = value\n",
        "        return profile\n",
        "\n",
        "    def store_conversation(user_id, text, metadata={}):\n",
        "        embedding = genai.embed_content(\n",
        "            model=\"models/embedding-001\",\n",
        "            content=text,\n",
        "            task_type=\"retrieval_document\"\n",
        "        )[\"embedding\"]\n",
        "\n",
        "        index.upsert(\n",
        "            vectors=[{\n",
        "                \"id\": f\"conv_{datetime.now().timestamp()}\",\n",
        "                \"values\": embedding,\n",
        "                \"metadata\": {\n",
        "                    \"user_id\": user_id,\n",
        "                    \"timestamp\": datetime.now().isoformat(),\n",
        "                    **{k: str(v) for k,v in metadata.items()}\n",
        "                }\n",
        "            }],\n",
        "            namespace=\"tax_conversations\"\n",
        "        )\n",
        "\n",
        "    def get_previous_context(user_id, query, top_k=3):\n",
        "        query_embed = genai.embed_content(\n",
        "            model=\"models/embedding-001\",\n",
        "            content=query,\n",
        "            task_type=\"retrieval_query\"\n",
        "        )[\"embedding\"]\n",
        "\n",
        "        results = index.query(\n",
        "            vector=query_embed,\n",
        "            top_k=top_k,\n",
        "            namespace=\"tax_conversations\",\n",
        "            filter={\"user_id\": {\"$eq\": user_id}},\n",
        "            include_metadata=True\n",
        "        )\n",
        "        return [match.metadata for match in results.matches]\n",
        "\n",
        "    # ====== TAX TOOLS ======\n",
        "    def analyze_deductions(profile):\n",
        "        applicable = []\n",
        "        if any(inv in profile[\"investments\"] for inv in [\"PPF\", \"ELSS\", \"FD\"]):\n",
        "            applicable.append({\n",
        "                \"section\": \"80C\",\n",
        "                \"max_amount\": 150000,\n",
        "                \"description\": \"Investments in specified instruments\"\n",
        "            })\n",
        "        if profile.get(\"health_insurance\"):\n",
        "            applicable.append({\n",
        "                \"section\": \"80D\",\n",
        "                \"max_amount\": 50000 if profile[\"age\"] > 60 else 25000,\n",
        "                \"description\": \"Health insurance premium\"\n",
        "            })\n",
        "        return applicable\n",
        "\n",
        "    update_cache = {\n",
        "        \"last_fetched\": None,\n",
        "        \"data\": None,\n",
        "        \"cache_duration\": timedelta(hours=1)\n",
        "    }\n",
        "\n",
        "    def get_tax_updates():\n",
        "        try:\n",
        "            if update_cache[\"last_fetched\"] and \\\n",
        "               (datetime.now() - update_cache[\"last_fetched\"]) < update_cache[\"cache_duration\"]:\n",
        "                return update_cache[\"data\"]\n",
        "\n",
        "            url = \"https://google.serper.dev/search\"\n",
        "            payload = json.dumps({\n",
        "                \"q\": \"site:incometaxindia.gov.in notification after:{date}\".format(\n",
        "                    date=(datetime.now() - timedelta(days=30)).strftime(\"%Y-%m-%d\")),\n",
        "                \"gl\": \"in\"\n",
        "            })\n",
        "            headers = {\n",
        "                'X-API-KEY': os.getenv(\"SERPER_API_KEY\", \"*******************************************************\"),\n",
        "                'Content-Type': 'application/json'\n",
        "            }\n",
        "\n",
        "            response = requests.post(url, headers=headers, data=payload, timeout=10)\n",
        "            response.raise_for_status()\n",
        "\n",
        "            updates = [{\n",
        "                \"title\": item[\"title\"],\n",
        "                \"link\": item[\"link\"],\n",
        "                \"snippet\": item.get(\"snippet\", \"\")\n",
        "            } for item in response.json().get(\"organic\", [])[:3]]\n",
        "\n",
        "            update_cache[\"data\"] = {\n",
        "                \"source\": \"IncomeTaxIndia.gov.in\",\n",
        "                \"updates\": updates,\n",
        "                \"last_checked\": datetime.now().isoformat()\n",
        "            }\n",
        "            update_cache[\"last_fetched\"] = datetime.now()\n",
        "\n",
        "            return update_cache[\"data\"]\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Update fetch failed: {str(e)}\")\n",
        "            return {\"error\": \"Could not fetch updates\"}\n",
        "\n",
        "    # ====== ADVANCED TAX TOOLS ======\n",
        "    def calculate_tax_savings(profile, deductions):\n",
        "        tax_slabs = {\n",
        "            \"5%\": 300000,\n",
        "            \"10%\": 500000,\n",
        "            \"15%\": 750000,\n",
        "            \"20%\": 1000000,\n",
        "            \"30%\": float('inf')\n",
        "        }\n",
        "\n",
        "        taxable_income = profile.get(\"annual_income\", 0)\n",
        "        current_slab = next((k for k,v in tax_slabs.items() if taxable_income <= v), \"30%\")\n",
        "        slab_rate = int(current_slab.strip('%')) / 100\n",
        "\n",
        "        return {\n",
        "            ded[\"section\"]: (\n",
        "                ded[\"max_amount\"],\n",
        "                ded[\"max_amount\"] * slab_rate\n",
        "            ) for ded in deductions\n",
        "        }\n",
        "\n",
        "    def optimize_investments(profile, available_cash):\n",
        "        suggestions = []\n",
        "\n",
        "        # 80C Optimization\n",
        "        remaining_80c = 150000 - profile[\"investments\"].get(\"80C\", 0)\n",
        "        if remaining_80c > 0 and available_cash > 0:\n",
        "            invest = min(remaining_80c, available_cash)\n",
        "            suggestions.append(\n",
        "                f\"Invest ₹{invest} in PPF/ELSS to maximize 80C (remaining limit: ₹{remaining_80c})\"\n",
        "            )\n",
        "            available_cash -= invest\n",
        "\n",
        "        # 80D Optimization\n",
        "        if profile.get(\"health_insurance\") and available_cash > 0:\n",
        "            limit = 50000 if profile[\"age\"] > 60 else 25000\n",
        "            current = profile[\"health_insurance\"].get(\"premium_amount\", 0)\n",
        "            remaining_80d = limit - current\n",
        "\n",
        "            if remaining_80d > 0:\n",
        "                invest = min(remaining_80d, available_cash)\n",
        "                suggestions.append(\n",
        "                    f\"Top-up health insurance by ₹{invest} (80D remaining limit: ₹{remaining_80d})\"\n",
        "                )\n",
        "\n",
        "        return suggestions or [\"No optimization needed - all limits utilized\"]\n",
        "\n",
        "    # ====== ENCRYPTION TOOLS ======\n",
        "    class SecureEncryptor:\n",
        "        def __init__(self, secret_key=None):\n",
        "            self.key = self._derive_key(secret_key or os.getenv(\"ENCRYPTION_SECRET\", \"your-strong-secret-key\"))\n",
        "\n",
        "        def _derive_key(self, password: str):\n",
        "            salt = b'salt_'  # Change this in production!\n",
        "            kdf = PBKDF2HMAC(\n",
        "                algorithm=hashes.SHA256(),\n",
        "                length=32,\n",
        "                salt=salt,\n",
        "                iterations=100000\n",
        "            )\n",
        "            return base64.urlsafe_b64encode(kdf.derive(password.encode()))\n",
        "\n",
        "        def encrypt(self, plaintext: str):\n",
        "            f = Fernet(self.key)\n",
        "            return f.encrypt(plaintext.encode()).decode()\n",
        "\n",
        "        def decrypt(self, ciphertext: str):\n",
        "            f = Fernet(self.key)\n",
        "            return f.decrypt(ciphertext.encode()).decode()\n",
        "\n",
        "        def rotate_keys(self):\n",
        "            new_key = Fernet.generate_key()\n",
        "            return new_key\n",
        "\n",
        "    encryptor = SecureEncryptor()\n",
        "\n",
        "    # ====== SESSION MANAGEMENT ======\n",
        "    def start_session(user_id):\n",
        "        active_sessions[user_id] = {\n",
        "            \"start_time\": datetime.now(),\n",
        "            \"message_count\": 0,\n",
        "            \"active_tools\": []\n",
        "        }\n",
        "        return f\"Session started for {user_id}\"\n",
        "\n",
        "    def end_session(user_id):\n",
        "        if user_id in active_sessions:\n",
        "            session_data = active_sessions.pop(user_id)\n",
        "            store_conversation(\n",
        "                user_id=user_id,\n",
        "                text=f\"Session ended after {session_data['message_count']} messages\",\n",
        "                metadata={\"type\": \"session_log\"}\n",
        "            )\n",
        "\n",
        "    def get_all_active_sessions():\n",
        "        return {\n",
        "            \"total_sessions\": len(active_sessions),\n",
        "            \"active_users\": list(active_sessions.keys()),\n",
        "            \"oldest_session\": min(sess[\"start_time\"] for sess in active_sessions.values())\n",
        "        }\n",
        "\n",
        "    # ====== SECURE PROFILE MANAGEMENT ======\n",
        "    def add_financial_details(user_id, details):\n",
        "        profile = get_user_profile(user_id)\n",
        "        sensitive_fields = [\"pan_number\", \"bank_account\", \"aadhaar\"]\n",
        "\n",
        "        for field in sensitive_fields:\n",
        "            if field in details:\n",
        "                details[field] = encryptor.encrypt(details[field])\n",
        "\n",
        "        profile.update(details)\n",
        "        return profile\n",
        "\n",
        "    def get_decrypted_details(user_id, fields):\n",
        "        profile = get_user_profile(user_id)\n",
        "        return {\n",
        "            field: encryptor.decrypt(profile[field])\n",
        "            for field in fields\n",
        "            if field in profile\n",
        "        }\n",
        "\n",
        "    # ====== MENU SYSTEM ======\n",
        "    def show_main_menu():\n",
        "        return \"\"\"🔍 How can I help with your taxes today?\n",
        "        1. Get deduction advice\n",
        "        2. Calculate tax liability\n",
        "        3. Optimize investments\n",
        "        4. Check latest tax updates\n",
        "        5. Manage profile\"\"\"\n",
        "\n",
        "    def handle_menu_selection(choice: int, user_id: str):\n",
        "        menu_actions = {\n",
        "            1: lambda: tax_chatbot(user_id, \"Get deduction advice\"),\n",
        "            2: lambda: tax_chatbot(user_id, \"Calculate my tax liability\"),\n",
        "            3: lambda: tax_chatbot(user_id, \"Optimize my investments\"),\n",
        "            4: lambda: get_tax_updates(),\n",
        "            5: lambda: \"Profile management selected\"\n",
        "        }\n",
        "        return menu_actions.get(choice, lambda: \"Invalid choice\")()\n",
        "\n",
        "    # ====== PERFORMANCE TOOLS ======\n",
        "    @lru_cache(maxsize=1000)\n",
        "    def get_tax_slab(income):\n",
        "        tax_slabs = {\n",
        "            (0, 300000): \"5%\",\n",
        "            (300001, 500000): \"10%\",\n",
        "            (500001, 750000): \"15%\",\n",
        "            (750001, 1000000): \"20%\",\n",
        "            (1000001, float('inf')): \"30%\"\n",
        "        }\n",
        "        for (lower, upper), slab in tax_slabs.items():\n",
        "            if lower <= income <= upper:\n",
        "                return slab\n",
        "        return \"30%\"\n",
        "\n",
        "    # ====== METRICS SETUP ======\n",
        "    REQUEST_COUNT = Counter('chatbot_requests_total', 'Total number of chatbot requests')\n",
        "    ERROR_COUNT = Counter('chatbot_errors_total', 'Total number of chatbot errors')\n",
        "    RESPONSE_TIME = Counter('chatbot_response_time_seconds', 'Total response time in seconds')\n",
        "\n",
        "    # ====== MAIN CHATBOT HANDLER ======\n",
        "    def tax_chatbot(user_id, query):\n",
        "        try:\n",
        "            METRICS['queries_processed'][user_id] += 1\n",
        "            start_time = time.time()\n",
        "\n",
        "            if user_id not in active_sessions:\n",
        "                start_session(user_id)\n",
        "\n",
        "            active_sessions[user_id][\"message_count\"] += 1\n",
        "\n",
        "            profile = get_user_profile(user_id)\n",
        "            context = get_previous_context(user_id, query)\n",
        "            updates = get_tax_updates()\n",
        "            deductions = analyze_deductions(profile)\n",
        "\n",
        "            prompt = f\"\"\"**Tax Expert Analysis**\\n\n",
        "            User Profile: {profile}\\n\n",
        "            Latest Updates: {updates}\\n\n",
        "            Previous Discussions: {context}\\n\\n\n",
        "            Question: {query}\\n\\n\n",
        "            Provide:\n",
        "            1. Relevant sections\n",
        "            2. Tax savings calculation\n",
        "            3. Optimization suggestions\"\"\"\n",
        "\n",
        "            needs_calculations = any(word in query.lower() for word in [\"save\", \"calculate\", \"optimize\"])\n",
        "\n",
        "            if needs_calculations:\n",
        "                calculations = calculate_tax_savings(profile, deductions)\n",
        "                optimizations = optimize_investments(profile, 100000)\n",
        "\n",
        "                prompt += \"\\n\\nAdditional Instructions:\\n\"\n",
        "                prompt += \"- Include exact tax savings calculations\\n\"\n",
        "                prompt += \"- Provide specific investment optimization suggestions\\n\"\n",
        "                prompt += \"- Format numbers clearly with ₹ symbol\"\n",
        "\n",
        "            response = model.generate_content(prompt)\n",
        "            response_text = response.text\n",
        "\n",
        "            if needs_calculations:\n",
        "                calculations = calculate_tax_savings(profile, deductions)\n",
        "                optimizations = optimize_investments(profile, 100000)\n",
        "\n",
        "                response_text += \"\\n\\n🔢 **Detailed Calculations:**\\n\"\n",
        "                for section, (amount, savings) in calculations.items():\n",
        "                    response_text += f\"- {section}: ₹{amount} → Saves ₹{savings:.0f}/year\\n\"\n",
        "\n",
        "                response_text += \"\\n💡 **Optimization Suggestions:**\\n\"\n",
        "                response_text += \"\\n\".join(f\"- {s}\" for s in optimizations)\n",
        "\n",
        "            store_conversation(\n",
        "                user_id=user_id,\n",
        "                text=f\"Q: {query}\\nA: {response_text}\",\n",
        "                metadata={\n",
        "                    \"type\": \"tax_advice\",\n",
        "                    \"session_id\": hash(user_id),\n",
        "                    \"message_num\": active_sessions[user_id][\"message_count\"]\n",
        "                }\n",
        "            )\n",
        "\n",
        "            METRICS['response_time'][user_id] = time.time() - start_time\n",
        "            return response_text\n",
        "\n",
        "        except Exception as e:\n",
        "            METRICS['errors'][str(e)] += 1\n",
        "            error_msg = f\"Error processing query: {str(e)}\"\n",
        "            print(error_msg)\n",
        "            return error_msg\n",
        "\n",
        "    # ====== WEB SERVER SETUP ======\n",
        "    app = FastAPI()\n",
        "    start_http_server(8001)\n",
        "\n",
        "    oauth2_scheme = OAuth2PasswordBearer(tokenUrl=\"token\")\n",
        "\n",
        "    async def get_current_user(token: str = Depends(oauth2_scheme)):\n",
        "        return {\"user_id\": \"test_user\"}\n",
        "\n",
        "    @app.post(\"/chat\")\n",
        "    async def chat_endpoint(user_id: str, query: str):\n",
        "        start_time = time.time()\n",
        "        REQUEST_COUNT.inc()\n",
        "        try:\n",
        "            response = tax_chatbot(user_id, query)\n",
        "            RESPONSE_TIME.inc(time.time() - start_time)\n",
        "            return {\"response\": response}\n",
        "        except Exception as e:\n",
        "            ERROR_COUNT.inc()\n",
        "            raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "    @app.post(\"/async-chat\")\n",
        "    async def async_chat(user_id: str, query: str):\n",
        "        return await asyncio.to_thread(tax_chatbot, user_id, query)\n",
        "\n",
        "    # ====== DATABASE SETUP ======\n",
        "    def init_db():\n",
        "        conn = sqlite3.connect('tax_chatbot.db')\n",
        "        c = conn.cursor()\n",
        "        c.execute('''CREATE TABLE IF NOT EXISTS users\n",
        "                    (user_id TEXT PRIMARY KEY, profile TEXT)''')\n",
        "        conn.commit()\n",
        "        conn.close()\n",
        "\n",
        "    # ====== FORM 16 PROCESSOR ======\n",
        "    def extract_form16_data(pdf_path):\n",
        "        text = extract_text(pdf_path)\n",
        "        return model.generate_content(f\"\"\"\n",
        "        Extract tax details from this Form 16:\n",
        "        {text}\n",
        "\n",
        "        Return JSON with: employer_name, salary_breakdown, tds_details\n",
        "        \"\"\")\n",
        "\n",
        "    # ====== TRANSLATION SUPPORT ======\n",
        "    def translate_response(response, target_language=\"hi\"):\n",
        "        if target_language == \"en\":\n",
        "            return response\n",
        "        return model.generate_content(f\"\"\"\n",
        "        Translate this tax advice to {target_language}:\n",
        "        {response}\n",
        "\n",
        "        Maintain technical accuracy while translating.\n",
        "        \"\"\")\n",
        "\n",
        "    # ====== TEST FLOW ======\n",
        "    print(\"\\n🚀 Testing complete flow...\")\n",
        "    init_db()\n",
        "\n",
        "    # Setup test user\n",
        "    test_user = \"test_user_001\"\n",
        "    update_profile(\n",
        "        get_user_profile(test_user),\n",
        "        {\n",
        "            \"investments\": {\"PPF\": 150000, \"ELSS\": 50000},\n",
        "            \"health_insurance\": True,\n",
        "            \"age\": 45,\n",
        "            \"annual_income\": 900000\n",
        "        }\n",
        "    )\n",
        "\n",
        "    # Test menu system\n",
        "    print(\"\\n📋 Testing menu system:\")\n",
        "    print(show_main_menu())\n",
        "    print(handle_menu_selection(1, test_user)[:200] + \"...\")\n",
        "\n",
        "    # Test basic query\n",
        "    print(\"\\n💬 Testing basic tax advice:\")\n",
        "    basic_response = tax_chatbot(test_user, \"How do recent notifications affect my 80D claims with ₹25k premium?\")\n",
        "    print(basic_response[:500] + \"...\")\n",
        "\n",
        "    # Test optimization query\n",
        "    print(\"\\n🧪 Testing optimization features:\")\n",
        "    optimization_response = tax_chatbot(test_user, \"How can I optimize ₹1,00,000 for maximum tax savings?\")\n",
        "    print(optimization_response)\n",
        "\n",
        "    # Test encryption\n",
        "    print(\"\\n🔒 Testing encryption:\")\n",
        "    user_data = {\n",
        "        \"pan_number\": \"ABCDE1234F\",\n",
        "        \"bank_account\": \"1234567890\"\n",
        "    }\n",
        "    updated = add_financial_details(\"secure_user\", user_data)\n",
        "    decrypted = get_decrypted_details(\"secure_user\", [\"pan_number\"])\n",
        "    print(f\"Original: {user_data['pan_number']}\")\n",
        "    print(f\"Encrypted: {updated['pan_number']}\")\n",
        "    print(f\"Decrypted: {decrypted['pan_number']}\")\n",
        "\n",
        "    print(\"\\n✅ All tests completed successfully!\")\n",
        "\n",
        "    # Start server (commented for notebook)\n",
        "    # if __name__ == \"__main__\":\n",
        "    #     uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n❌ Critical error: {str(e)}\")\n",
        "    print(\"Immediate actions:\")\n",
        "    print(\"1. RESTART RUNTIME (Runtime → Restart runtime)\")\n",
        "    print(\"2. Check API keys are valid\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "8WdC1g6SnFjp",
        "outputId": "ae222b2b-894c-4c33-dc40-576570a9af45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔌 Initializing APIs...\n",
            "🗑️ Deleted old index\n",
            "✅ Created index (768 dim)\n",
            "\n",
            "🚀 Testing complete flow...\n",
            "\n",
            "📋 Testing menu system:\n",
            "🔍 How can I help with your taxes today?\n",
            "        1. Get deduction advice\n",
            "        2. Calculate tax liability\n",
            "        3. Optimize investments\n",
            "        4. Check latest tax updates\n",
            "        5. Manage profile\n",
            "## Tax Deduction Advice based on Provided Information\n",
            "\n",
            "**1. Relevant Sections:**\n",
            "\n",
            "Based on the user profile, the following sections are relevant for tax deductions:\n",
            "\n",
            "* **Section 80C:** Deductions for ...\n",
            "\n",
            "💬 Testing basic tax advice:\n",
            "Here's an analysis based on the provided information:\n",
            "\n",
            "**1. Relevant Sections:**\n",
            "\n",
            "The user's question pertains to Section 80D of the Income Tax Act, which deals with deductions for health insurance premiums.  Specifically, the question asks about the impact of *recent notifications*.  While the provided updates mention new notifications (e.g., Notification No. 30/2025), the snippets don't offer details about changes specifically to Section 80D.  Therefore, we need to analyze based on the *genera...\n",
            "\n",
            "🧪 Testing optimization features:\n",
            "## Tax Optimization for ₹1,00,000 (FY 2025-26 - Assuming based on the latest update date)\n",
            "\n",
            "Given the user's current investments in PPF (₹1,50,000) and ELSS (₹50,000), and an additional ₹1,00,000 to invest, we'll explore optimization strategies under Section 80C and other relevant sections.  We're assuming the user is a resident individual for tax purposes.\n",
            "\n",
            "**1. Relevant Sections:**\n",
            "\n",
            "* **Section 80C:** Deduction up to ₹1,50,000 for investments in specified schemes like PPF, ELSS, life insurance premiums, etc.\n",
            "* **Section 80D:** Deduction for health insurance premiums (up to ₹25,000 for self, spouse, and children; up to ₹50,000 for senior citizen parents).\n",
            "* **Section 80CCD(1B):** Deduction up to ₹50,000 for contributions to the National Pension System (NPS).\n",
            "\n",
            "**2. Tax Savings Calculation:**\n",
            "\n",
            "The user is already investing ₹2,00,000 (PPF + ELSS) which exceeds the ₹1,50,000 limit under Section 80C. Therefore, simply investing the additional ₹1,00,000 in 80C instruments won't provide further tax benefits under this section.  We need to consider other avenues.\n",
            "\n",
            "**3. Optimization Suggestions:**\n",
            "\n",
            "Since the user's 80C limit is already maxed out, here's how to optimize the ₹1,00,000 for maximum tax savings:\n",
            "\n",
            "* **Health Insurance (Section 80D):** If the user doesn't have adequate health insurance coverage, allocating a portion of the ₹1,00,000 towards a comprehensive health insurance policy for themselves and their family is highly recommended. This will provide both tax benefits and crucial financial protection.  Assuming a premium of ₹25,000, this will result in a tax saving based on the user's tax slab.\n",
            "* **National Pension System (NPS) [Section 80CCD(1B)]:** Investing up to ₹50,000 in NPS offers an additional deduction beyond Section 80C.  This investment can lead to additional tax savings depending on the user's tax slab.\n",
            "* **Remaining Amount:** The remaining amount (₹1,00,000 - Health Insurance Premium - NPS Contribution) can be considered for other investments like debt funds (for relatively stable returns) or equity funds (for potentially higher but riskier returns). While these won't offer immediate tax deductions, they can contribute to long-term wealth creation.\n",
            "\n",
            "\n",
            "**Example Scenario:**\n",
            "\n",
            "Let's assume the user invests:\n",
            "\n",
            "* **₹25,000** in Health Insurance (Section 80D)\n",
            "* **₹50,000** in NPS (Section 80CCD(1B))\n",
            "* **₹25,000** in a Debt Mutual Fund\n",
            "\n",
            "**Tax Savings Calculation (Illustrative):**\n",
            "\n",
            "Assuming the user falls in the 30% tax bracket:\n",
            "\n",
            "* **80D Saving:** ₹25,000 * 30% = ₹7,500\n",
            "* **80CCD(1B) Saving:** ₹50,000 * 30% = ₹15,000\n",
            "* **Total Tax Saving:** ₹7,500 + ₹15,000 = ₹22,500\n",
            "\n",
            "**Note:**\n",
            "\n",
            "* The exact tax savings will depend on the user's income and applicable tax slab.\n",
            "* The investment recommendations are general in nature.  A qualified financial advisor should be consulted for personalized advice.\n",
            "*  The specific rules and limits for tax deductions are subject to change and it's important to verify the latest regulations for the relevant financial year.\n",
            "* We have assumed the financial year 2025-26 based on the \"Latest Updates\" information provided.  However, confirming the current financial year is crucial for accurate advice.\n",
            "\n",
            "\n",
            "This analysis provides a framework for optimizing the ₹1,00,000.  Gathering further details about the user's income, existing insurance coverage, and financial goals would enable a more precise and tailored recommendation.\n",
            "\n",
            "\n",
            "🔢 **Detailed Calculations:**\n",
            "- 80C: ₹150000 → Saves ₹7500/year\n",
            "\n",
            "💡 **Optimization Suggestions:**\n",
            "- Invest ₹100000 in PPF/ELSS to maximize 80C (remaining limit: ₹150000)\n",
            "\n",
            "🔒 Testing encryption:\n",
            "Original: gAAAAABoBxcB4KaiVaEoWdDZSutNL_vcKn04AK953IaE9SGL2PQ4HfAQamHbj2YAmVHGGuYIB7Au0yZ6OVuO1I6ekGSw7VvO1Q==\n",
            "Encrypted: gAAAAABoBxcB4KaiVaEoWdDZSutNL_vcKn04AK953IaE9SGL2PQ4HfAQamHbj2YAmVHGGuYIB7Au0yZ6OVuO1I6ekGSw7VvO1Q==\n",
            "Decrypted: ABCDE1234F\n",
            "\n",
            "✅ All tests completed successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile main.py\n",
        "from fastapi import FastAPI\n",
        "app = FastAPI()\n",
        "\n",
        "# PASTE YOUR ENTIRE EXISTING FASTAPI CODE HERE\n",
        "# (from the working Colab cells where you defined your tax chatbot)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76OA1otJGQ47",
        "outputId": "7169fa70-93d3-49d0-ede9-52c987ee6921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing main.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "fastapi==0.109.1\n",
        "uvicorn==0.27.0\n",
        "python-multipart==0.0.6\n",
        "google-generativeai==0.3.2\n",
        "pinecone-client==3.0.2\n",
        "python-dotenv==1.0.0\n",
        "cryptography==42.0.2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZU-A0lnJh7H",
        "outputId": "76270f0a-ce32-46d9-83a4-3369a53e8648"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  # List all files in current Colab directory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AgaqHjVxIzsb",
        "outputId": "0b3f74c3-b14d-4220-fb7d-b19464c93968"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main.py  requirements.txt  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l  # Check exact capitalization (Main.py vs main.py)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1JOBNquj-pf",
        "outputId": "685d76da-3385-4d6c-dc0c-37bc5e7fd750"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 12\n",
            "-rw-r--r-- 1 root root  160 Apr 21 19:10 main.py\n",
            "-rw-r--r-- 1 root root  149 Apr 21 19:10 requirements.txt\n",
            "drwxr-xr-x 1 root root 4096 Apr 17 13:36 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create zip by explicitly listing files\n",
        "!zip tax_chatbot_project.zip main.py requirements.txt\n",
        "\n",
        "# Alternative if above fails:\n",
        "!zip tax_chatbot_project.zip *.py *.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIjnl1LJkXs4",
        "outputId": "e0dc12dc-1c95-43cf-8e3c-4368027ef1d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: main.py (deflated 15%)\n",
            "  adding: requirements.txt (deflated 23%)\n",
            "updating: main.py (deflated 15%)\n",
            "updating: requirements.txt (deflated 23%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  # Should show tax_chatbot_project.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0KHjWq9lIgK",
        "outputId": "05e0d5bd-a3a4-4fa5-a1b1-866a860e47c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "main.py  requirements.txt  sample_data\ttax_chatbot_project.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r tax_chatbot_project.zip main.py requirements.txt\n",
        "from google.colab import files\n",
        "files.download('tax_chatbot_project.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "dtHlwdZgjUzk",
        "outputId": "0e2e5ca4-ddf8-41d3-f936-4d07e1081406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: main.py (deflated 15%)\n",
            "updating: requirements.txt (deflated 23%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d94ca842-031c-4963-b255-919542576325\", \"tax_chatbot_project.zip\", 575)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn python-multipart pydantic\n",
        "!pip list | grep -E \"fastapi|uvicorn|pydantic\"\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "from datetime import datetime\n",
        "import logging\n",
        "\n",
        "# Initialize app\n",
        "app = FastAPI(\n",
        "    title=\"Indian Tax Chatbot API\",\n",
        "    description=\"API for personalized tax guidance with memory\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# Configure logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "# --- Data Models ---\n",
        "class UserProfile(BaseModel):\n",
        "    user_id: str\n",
        "    age: int\n",
        "    annual_income: float\n",
        "    investments: dict = {}\n",
        "    health_insurance: bool = False\n",
        "    housing_loan: bool = False\n",
        "\n",
        "class TaxQuery(BaseModel):\n",
        "    question: str\n",
        "    context: Optional[str] = None\n",
        "\n",
        "class OptimizationRequest(BaseModel):\n",
        "    available_amount: float\n",
        "    financial_goals: List[str] = []\n",
        "\n",
        "# --- Database Mock ---\n",
        "user_profiles_db = {}\n",
        "conversation_history = {}\n",
        "\n",
        "# --- Core Endpoints ---\n",
        "@app.post(\"/register\", summary=\"Register new user\")\n",
        "async def register_user(profile: UserProfile):\n",
        "    \"\"\"Store user profile with financial details\"\"\"\n",
        "    user_profiles_db[profile.user_id] = profile.dict()\n",
        "    logger.info(f\"New user registered: {profile.user_id}\")\n",
        "    return {\"status\": \"success\", \"user_id\": profile.user_id}\n",
        "\n",
        "@app.get(\"/profile/{user_id}\", response_model=UserProfile)\n",
        "async def get_profile(user_id: str):\n",
        "    \"\"\"Retrieve user profile\"\"\"\n",
        "    if user_id not in user_profiles_db:\n",
        "        raise HTTPException(status_code=404, detail=\"User not found\")\n",
        "    return user_profiles_db[user_id]\n",
        "\n",
        "@app.post(\"/ask\", summary=\"Get tax advice\")\n",
        "async def ask_tax_question(user_id: str, query: TaxQuery):\n",
        "    \"\"\"\n",
        "    Main tax advice endpoint with conversation memory\n",
        "    \"\"\"\n",
        "    profile = user_profiles_db.get(user_id, {})\n",
        "\n",
        "    # ACTUAL TAX LOGIC IMPLEMENTATION\n",
        "    tax_slabs = [\n",
        "        (0, 300000, 0),\n",
        "        (300001, 600000, 0.05),\n",
        "        (600001, 900000, 0.10),\n",
        "        (900001, 1200000, 0.15),\n",
        "        (1200001, 1500000, 0.20),\n",
        "        (1500001, float('inf'), 0.30)\n",
        "    ]\n",
        "\n",
        "    # Calculate deductions\n",
        "    deductions = {\n",
        "        '80C': min(150000, profile.get('investments', {}).get('80C', 0)),\n",
        "        '80D': 50000 if profile.get('age', 0) > 60 else 25000 if profile.get('health_insurance') else 0,\n",
        "        'NPS': min(50000, profile.get('investments', {}).get('NPS', 0))\n",
        "    }\n",
        "\n",
        "    response = {\n",
        "        \"answer\": f\"For {user_id}: {query.question}\",\n",
        "        \"suggestions\": [\n",
        "            f\"80C: ₹{deductions['80C']} available\",\n",
        "            f\"80D: ₹{deductions['80D']} deductible\",\n",
        "            f\"NPS: ₹{deductions['NPS']} contribution\"\n",
        "        ],\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    }\n",
        "\n",
        "    # Store conversation\n",
        "    if user_id not in conversation_history:\n",
        "        conversation_history[user_id] = []\n",
        "    conversation_history[user_id].append({\n",
        "        \"question\": query.question,\n",
        "        \"response\": response,\n",
        "        \"timestamp\": datetime.now().isoformat()\n",
        "    })\n",
        "\n",
        "    return response\n",
        "\n",
        "@app.post(\"/optimize\", summary=\"Tax optimization planner\")\n",
        "async def optimize_investments(user_id: str, request: OptimizationRequest):\n",
        "    \"\"\"ACTUAL OPTIMIZATION LOGIC\"\"\"\n",
        "    profile = user_profiles_db.get(user_id, {})\n",
        "    suggestions = []\n",
        "    remaining = request.available_amount\n",
        "\n",
        "    # 80C Optimization\n",
        "    used_80c = profile.get('investments', {}).get('80C', 0)\n",
        "    remaining_80c = max(0, 150000 - used_80c)\n",
        "    invest_80c = min(remaining_80c, remaining)\n",
        "    if invest_80c > 0:\n",
        "        suggestions.append(f\"Invest ₹{invest_80c} in ELSS (80C)\")\n",
        "        remaining -= invest_80c\n",
        "\n",
        "    # NPS Optimization\n",
        "    if remaining > 0:\n",
        "        invest_nps = min(50000, remaining)\n",
        "        suggestions.append(f\"Invest ₹{invest_nps} in NPS (80CCD(1B))\")\n",
        "        remaining -= invest_nps\n",
        "\n",
        "    return {\n",
        "        \"optimization_plan\": suggestions,\n",
        "        \"estimated_savings\": (request.available_amount - remaining) * 0.3,\n",
        "        \"remaining_amount\": remaining\n",
        "    }\n",
        "\n",
        "# --- Technical Endpoints ---\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    return {\"status\": \"healthy\"}\n",
        "\n",
        "# --- CORS Setup ---\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SS7QQtDkulA_",
        "outputId": "8ba668cb-7764-4866-a778-fbe98513247d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.34.2)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.11/dist-packages (0.0.20)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.11.3)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "fastapi                               0.115.12\n",
            "pydantic                              2.11.3\n",
            "pydantic_core                         2.33.1\n",
            "uvicorn                               0.34.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uvicorn main:app --reload --host 0.0.0.0 --port 8000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0Bftow_vtEX",
        "outputId": "e58b34f7-b0dc-4e8c-bf9c-3204fc862e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32mINFO\u001b[0m:     Will watch for changes in these directories: ['/content']\n",
            "\u001b[32mINFO\u001b[0m:     Uvicorn running on \u001b[1mhttp://0.0.0.0:8000\u001b[0m (Press CTRL+C to quit)\n",
            "\u001b[32mINFO\u001b[0m:     Started reloader process [\u001b[36m\u001b[1m25519\u001b[0m] using \u001b[36m\u001b[1mStatReload\u001b[0m\n",
            "\u001b[32mINFO\u001b[0m:     Started server process [\u001b[36m25525\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application startup.\n",
            "\u001b[32mINFO\u001b[0m:     Application startup complete.\n",
            "\u001b[32mINFO\u001b[0m:     Shutting down\n",
            "\u001b[32mINFO\u001b[0m:     Waiting for application shutdown.\n",
            "\u001b[32mINFO\u001b[0m:     Application shutdown complete.\n",
            "\u001b[32mINFO\u001b[0m:     Finished server process [\u001b[36m25525\u001b[0m]\n",
            "\u001b[32mINFO\u001b[0m:     Stopping reloader process [\u001b[36m\u001b[1m25519\u001b[0m]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok --quiet\n",
        "from fastapi import FastAPI\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "\n",
        "# Initialize app\n",
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def home():\n",
        "    return {\"status\": \"API is running\"}\n",
        "\n",
        "# Configure ngrok (replace with your token)\n",
        "NGROK_TOKEN = \"*******************************************************\"  # ← Paste your token here\n",
        "ngrok.set_auth_token(NGROK_TOKEN)\n",
        "\n",
        "# Start tunnel\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "print(f\"🌐 Public URL: {public_url}\")\n",
        "\n",
        "# Start FastAPI\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "id": "0R2hmKxlysBU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastapi uvicorn pyngrok nest-asyncio python-multipart --quiet\n",
        "\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from typing import List, Optional\n",
        "from pyngrok import ngrok\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "import threading\n",
        "from datetime import datetime\n",
        "\n",
        "# ====== FASTAPI SETUP ======\n",
        "app = FastAPI(title=\"Tax Chatbot API\", version=\"1.0\")\n",
        "\n",
        "# ====== TAX ENDPOINTS ======\n",
        "class TaxRequest(BaseModel):\n",
        "    income: float\n",
        "    age: int\n",
        "    investments: dict = {\"80C\": 0, \"NPS\": 0}\n",
        "    health_insurance: bool = False\n",
        "\n",
        "@app.post(\"/calculate\")\n",
        "def calculate_tax(data: TaxRequest):\n",
        "    \"\"\"Real Indian tax calculation\"\"\"\n",
        "    # Deductions\n",
        "    deductions = {\n",
        "        '80C': min(150000, data.investments.get(\"80C\", 0)),\n",
        "        '80D': 50000 if data.age > 60 else 25000 if data.health_insurance else 0,\n",
        "        'NPS': min(50000, data.investments.get(\"NPS\", 0))\n",
        "    }\n",
        "\n",
        "    # Tax slabs (2024-25)\n",
        "    taxable_income = data.income - sum(deductions.values())\n",
        "    tax = 0\n",
        "    for min_val, max_val, rate in [\n",
        "        (0, 300000, 0),\n",
        "        (300001, 600000, 0.05),\n",
        "        (600001, 900000, 0.10),\n",
        "        (900001, 1200000, 0.15),\n",
        "        (1200001, 1500000, 0.20),\n",
        "        (1500001, float('inf'), 0.30)\n",
        "    ]:\n",
        "        if taxable_income > min_val:\n",
        "            tax += (min(taxable_income, max_val) - min_val) * rate\n",
        "\n",
        "    return {\n",
        "        \"taxable_income\": taxable_income,\n",
        "        \"total_tax\": tax,\n",
        "        \"effective_rate\": (tax/data.income)*100,\n",
        "        \"deductions\": deductions\n",
        "    }\n",
        "\n",
        "# ====== SERVER LAUNCH ======\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000)\n",
        "\n",
        "# Start in background\n",
        "thread = threading.Thread(target=run_server, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "ngrok.set_auth_token(\"*******************************************************\")  # Get from https://dashboard.ngrok.com\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "\n",
        "print(f\"\\n✅ Tax API Ready!\\n\"\n",
        "      f\"• Test URL: {public_url}/calculate\\n\"\n",
        "      f\"• Docs: {public_url}/docs\\n\\n\"\n",
        "      \"Keep this cell running to maintain the connection.\")\n",
        "\n",
        "# Keep alive\n",
        "while True: pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPcCGWMV7s6z",
        "outputId": "3b916ca1-9c98-4aaf-9101-cdf06c8809d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [3004]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "✅ Tax API Ready!\n",
            "• Test URL: https://0264-34-125-68-33.ngrok-free.app/calculate\n",
            "• Docs: https://0264-34-125-68-33.ngrok-free.app/docs\n",
            "\n",
            "Keep this cell running to maintain the connection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prevent Colab timeouts\n",
        "from IPython.display import Javascript\n",
        "Javascript(\"\"\"\n",
        "function keepAlive() {\n",
        "    console.log(\"Keeping session alive\");\n",
        "}\n",
        "setInterval(keepAlive, 60000);\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "yCmc12IqAACq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== IMPORTS ======\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from typing import Dict\n",
        "\n",
        "# ====== APP SETUP ======\n",
        "app = FastAPI(title=\"Tax Calculator API\", version=\"1.0\")\n",
        "\n",
        "# ====== DATA MODELS ======\n",
        "class TaxRequest(BaseModel):\n",
        "    income: float\n",
        "    age: int\n",
        "    investments: Dict[str, float] = {\"80C\": 0, \"NPS\": 0}\n",
        "    health_insurance: bool = False\n",
        "\n",
        "# ====== TAX CALCULATION LOGIC ======\n",
        "def calculate_tax_from_slabs(income: float) -> float:\n",
        "    \"\"\"Calculate tax based on Indian income tax slabs (2024-25)\"\"\"\n",
        "    tax = 0\n",
        "    for min_val, max_val, rate in [\n",
        "        (0, 300000, 0),\n",
        "        (300001, 600000, 0.05),\n",
        "        (600001, 900000, 0.10),\n",
        "        (900001, 1200000, 0.15),\n",
        "        (1200001, 1500000, 0.20),\n",
        "        (1500001, float('inf'), 0.30)\n",
        "    ]:\n",
        "        if income > min_val:\n",
        "            taxable = min(income, max_val) - min_val\n",
        "            tax += taxable * rate\n",
        "    return tax\n",
        "\n",
        "# ====== API ENDPOINT ======\n",
        "@app.post(\"/calculate\")\n",
        "def calculate_tax(data: TaxRequest):\n",
        "    # Validate investments keys\n",
        "    if not all(k in [\"80C\", \"NPS\"] for k in data.investments.keys()):\n",
        "        raise HTTPException(\n",
        "            status_code=422,\n",
        "            detail=\"Investments must contain only '80C' and/or 'NPS' keys\"\n",
        "        )\n",
        "\n",
        "    # Calculate deductions\n",
        "    deductions = {\n",
        "        '80C': min(150000, data.investments.get(\"80C\", 0)),\n",
        "        '80D': 50000 if data.age > 60 else 25000 if data.health_insurance else 0,\n",
        "        'NPS': min(50000, data.investments.get(\"NPS\", 0))\n",
        "    }\n",
        "\n",
        "    # Tax calculation\n",
        "    taxable_income = data.income - sum(deductions.values())\n",
        "    total_tax = calculate_tax_from_slabs(taxable_income)\n",
        "\n",
        "    return {\n",
        "        \"taxable_income\": taxable_income,\n",
        "        \"total_tax\": total_tax,\n",
        "        \"effective_rate\": (total_tax / data.income) * 100,\n",
        "        \"deductions\": deductions\n",
        "    }\n",
        "\n",
        "# ====== ROOT ENDPOINT ======\n",
        "@app.get(\"/\")\n",
        "def home():\n",
        "    return {\"message\": \"Tax Calculator API - Use /calculate endpoint\"}\n",
        "!curl -X POST \"http://localhost:8000/calculate\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d '{\"income\":1500000,\"age\":35,\"investments\":{\"80C\":150000,\"NPS\":50000},\"health_insurance\":true}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUpsRVSiCeE7",
        "outputId": "82b7743e-0110-4810-ac43-0004638a55cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curl: (7) Failed to connect to localhost port 8000 after 0 ms: Connection refused\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====== 1. INSTALL DEPENDENCIES ======\n",
        "!pip install fastapi uvicorn pyngrok nest-asyncio python-multipart --quiet\n",
        "!pkill -f \"uvicorn\"  # Kill any existing servers\n",
        "\n",
        "# ====== 2. FASTAPI SETUP ======\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from typing import Dict\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import threading\n",
        "import time\n",
        "\n",
        "app = FastAPI(\n",
        "    title=\"Indian Tax Calculator API\",\n",
        "    version=\"2.0\",\n",
        "    description=\"Accurate Indian tax calculations with slab rates (2024-25)\"\n",
        ")\n",
        "\n",
        "# ====== 3. TAX CALCULATION ======\n",
        "class TaxRequest(BaseModel):\n",
        "    income: float\n",
        "    age: int\n",
        "    investments: Dict[str, float] = {\"80C\": 0, \"NPS\": 0}\n",
        "    health_insurance: bool = False\n",
        "\n",
        "def calculate_tax_from_slabs(income: float) -> float:\n",
        "    tax = 0\n",
        "    for min_val, max_val, rate in [\n",
        "        (0, 300000, 0), (300001, 600000, 0.05),\n",
        "        (600001, 900000, 0.10), (900001, 1200000, 0.15),\n",
        "        (1200001, 1500000, 0.20), (1500001, float('inf'), 0.30)\n",
        "    ]:\n",
        "        if income > min_val:\n",
        "            tax += (min(income, max_val) - min_val) * rate\n",
        "    return tax * 1.04  # 4% cess\n",
        "\n",
        "@app.post(\"/calculate\")\n",
        "def calculate_tax(data: TaxRequest):\n",
        "    # Validate input\n",
        "    if data.income <= 0:\n",
        "        raise HTTPException(400, \"Income must be positive\")\n",
        "\n",
        "    # CORRECTED DEDUCTION CALCULATION\n",
        "    deductions = {\n",
        "        '80C': min(150000, data.investments.get(\"80C\", 0)),  # Max ₹1.5L\n",
        "        '80D': 50000 if data.age > 60 else 25000 if data.health_insurance else 0,  # Senior citizen check\n",
        "        'NPS': min(50000, data.investments.get(\"NPS\", 0))  # Max ₹50K\n",
        "    }\n",
        "\n",
        "    taxable_income = max(0, data.income - sum(deductions.values()))\n",
        "    tax = calculate_tax_from_slabs(taxable_income)\n",
        "\n",
        "    # ENSURE CORRECT FIELD NAMES IN RESPONSE\n",
        "    return {\n",
        "        \"taxable_income\": taxable_income,\n",
        "        \"total_tax\": tax,\n",
        "        \"effective_rate\": (tax / data.income) * 100,\n",
        "        \"deductions\": {\n",
        "            \"80C\": deductions['80C'],  # Will now correctly show \"80C\"\n",
        "            \"80D\": deductions['80D'],  # Will now correctly show \"80D\"\n",
        "            \"NPS\": deductions['NPS']\n",
        "        }\n",
        "    }\n",
        "# ====== 4. SERVER LAUNCH ======\n",
        "def run_server():\n",
        "    uvicorn.run(app, host=\"0.0.0.0\", port=8000, log_level=\"warning\")\n",
        "\n",
        "# Cleanup and start\n",
        "ngrok.kill()  # Clear old tunnels\n",
        "ngrok.set_auth_token(\"*******************************************************\")\n",
        "public_url = ngrok.connect(8000).public_url\n",
        "\n",
        "nest_asyncio.apply()\n",
        "thread = threading.Thread(target=run_server, daemon=True)\n",
        "thread.start()\n",
        "\n",
        "# Wait for server startup\n",
        "time.sleep(3)\n",
        "\n",
        "print(f\"\"\"\n",
        "✅ API READY!\n",
        "• Local: http://localhost:8000\n",
        "• Public: {public_url}\n",
        "• Docs: {public_url}/docs\n",
        "\n",
        "Test with:\n",
        "curl -X POST '{public_url}/calculate' \\\\\n",
        "  -H 'Content-Type: application/json' \\\\\n",
        "  -d '{{\"income\":1500000,\"age\":35,\"investments\":{{\"80C\":150000,\"NPS\":50000}},\"health_insurance\":true}}'\n",
        "\"\"\")\n",
        "\n",
        "# Keep alive without while True\n",
        "from IPython.display import display, Javascript\n",
        "display(Javascript('''\n",
        "function keepAlive() {\n",
        "    fetch(\"http://localhost:8000\").catch(console.log)\n",
        "}\n",
        "setInterval(keepAlive, 30000)\n",
        "'''))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "id": "NCQ-g-t_Gm62",
        "outputId": "8145b87e-af0f-419f-a73b-caa8e1491681"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/62.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\n",
            "✅ API READY!\n",
            "• Local: http://localhost:8000\n",
            "• Public: https://86ce-34-125-68-33.ngrok-free.app\n",
            "• Docs: https://86ce-34-125-68-33.ngrok-free.app/docs\n",
            "\n",
            "Test with:\n",
            "curl -X POST 'https://86ce-34-125-68-33.ngrok-free.app/calculate' \\\n",
            "  -H 'Content-Type: application/json' \\\n",
            "  -d '{\"income\":1500000,\"age\":35,\"investments\":{\"80C\":150000,\"NPS\":50000},\"health_insurance\":true}'\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "function keepAlive() {\n",
              "    fetch(\"http://localhost:8000\").catch(console.log)\n",
              "}\n",
              "setInterval(keepAlive, 30000)\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile frontend.html\n",
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head>\n",
        "    <title>Tax Calculator</title>\n",
        "    <style>\n",
        "        body { font-family: Arial; max-width: 500px; margin: 0 auto; padding: 20px; }\n",
        "        input, button { padding: 8px; margin: 5px 0; width: 100%; }\n",
        "        button { background: #4CAF50; color: white; border: none; cursor: pointer; }\n",
        "        #result { margin-top: 20px; padding: 10px; background: #f5f5f5; }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <h2>Tax Calculator</h2>\n",
        "    <form id=\"taxForm\">\n",
        "        <input type=\"number\" name=\"income\" placeholder=\"Annual Income (₹)\" required>\n",
        "        <input type=\"number\" name=\"age\" placeholder=\"Age\" required>\n",
        "        <h3>Investments</h3>\n",
        "        <input type=\"number\" name=\"80C\" placeholder=\"80C Investment (Max ₹1.5L)\">\n",
        "        <input type=\"number\" name=\"NPS\" placeholder=\"NPS Investment (Max ₹50K)\">\n",
        "        <label>\n",
        "            <input type=\"checkbox\" name=\"health_insurance\"> Health Insurance?\n",
        "        </label>\n",
        "        <button type=\"submit\">Calculate Tax</button>\n",
        "    </form>\n",
        "    <div id=\"result\"></div>\n",
        "\n",
        "    <script>\n",
        "        document.getElementById(\"taxForm\").onsubmit = async (e) => {\n",
        "            e.preventDefault();\n",
        "            const formData = new FormData(e.target);\n",
        "\n",
        "            const response = await fetch(\"https://YOUR_NGROK_URL/calculate\", {\n",
        "                method: \"POST\",\n",
        "                headers: { \"Content-Type\": \"application/json\" },\n",
        "                body: JSON.stringify({\n",
        "                    income: parseFloat(formData.get(\"income\")),\n",
        "                    age: parseInt(formData.get(\"age\")),\n",
        "                    investments: {\n",
        "                        \"80C\": parseFloat(formData.get(\"80C\") || 0,\n",
        "                        \"NPS\": parseFloat(formData.get(\"NPS\") || 0\n",
        "                    },\n",
        "                    health_insurance: formData.get(\"health_insurance\") === \"on\"\n",
        "                })\n",
        "            });\n",
        "\n",
        "            const data = await response.json();\n",
        "            document.getElementById(\"result\").innerHTML = `\n",
        "                <h3>Results</h3>\n",
        "                <p>Taxable Income: ₹${data.taxable_income.toLocaleString()}</p>\n",
        "                <p>Total Tax: ₹${data.total_tax.toLocaleString()}</p>\n",
        "                <p>Effective Rate: ${data.effective_rate.toFixed(2)}%</p>\n",
        "                <h4>Deductions Applied:</h4>\n",
        "                <ul>\n",
        "                    <li>80C: ₹${data.deductions['80C'].toLocaleString()}</li>\n",
        "                    <li>80D: ₹${data.deductions['80D'].toLocaleString()}</li>\n",
        "                    <li>NPS: ₹${data.deductions['NPS'].toLocaleString()}</li>\n",
        "                </ul>\n",
        "            `;\n",
        "        };\n",
        "    </script>\n",
        "</body>\n",
        "</html>"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G7-80BFIOePx",
        "outputId": "80f2d5fc-8cfc-4133-da1f-911c9358aa57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting frontend.html\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab.output import eval_js\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "display(HTML('''\n",
        "<script>\n",
        "    window.open(\" https://15a1-34-125-68-33.ngrok-free.app/docs\", \"_blank\");\n",
        "</script>\n",
        "'''))\n",
        "\n",
        "# Serve the frontend\n",
        "display(HTML(filename='frontend.html'))"
      ],
      "metadata": {
        "id": "QE2wq2d5OizN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 420
        },
        "outputId": "79208e1c-1944-4623-8f16-5eed9ce3178a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<script>\n",
              "    window.open(\" https://15a1-34-125-68-33.ngrok-free.app/docs\", \"_blank\");\n",
              "</script>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<!DOCTYPE html>\n",
              "<html>\n",
              "<head>\n",
              "    <title>Tax Calculator</title>\n",
              "    <style>\n",
              "        body { font-family: Arial; max-width: 500px; margin: 0 auto; padding: 20px; }\n",
              "        input, button { padding: 8px; margin: 5px 0; width: 100%; }\n",
              "        button { background: #4CAF50; color: white; border: none; cursor: pointer; }\n",
              "        #result { margin-top: 20px; padding: 10px; background: #f5f5f5; }\n",
              "    </style>\n",
              "</head>\n",
              "<body>\n",
              "    <h2>Tax Calculator</h2>\n",
              "    <form id=\"taxForm\">\n",
              "        <input type=\"number\" name=\"income\" placeholder=\"Annual Income (₹)\" required>\n",
              "        <input type=\"number\" name=\"age\" placeholder=\"Age\" required>\n",
              "        <h3>Investments</h3>\n",
              "        <input type=\"number\" name=\"80C\" placeholder=\"80C Investment (Max ₹1.5L)\">\n",
              "        <input type=\"number\" name=\"NPS\" placeholder=\"NPS Investment (Max ₹50K)\">\n",
              "        <label>\n",
              "            <input type=\"checkbox\" name=\"health_insurance\"> Health Insurance?\n",
              "        </label>\n",
              "        <button type=\"submit\">Calculate Tax</button>\n",
              "    </form>\n",
              "    <div id=\"result\"></div>\n",
              "\n",
              "    <script>\n",
              "        document.getElementById(\"taxForm\").onsubmit = async (e) => {\n",
              "            e.preventDefault();\n",
              "            const formData = new FormData(e.target);\n",
              "\n",
              "            const response = await fetch(\"https://YOUR_NGROK_URL/calculate\", {\n",
              "                method: \"POST\",\n",
              "                headers: { \"Content-Type\": \"application/json\" },\n",
              "                body: JSON.stringify({\n",
              "                    income: parseFloat(formData.get(\"income\")),\n",
              "                    age: parseInt(formData.get(\"age\")),\n",
              "                    investments: {\n",
              "                        \"80C\": parseFloat(formData.get(\"80C\") || 0,\n",
              "                        \"NPS\": parseFloat(formData.get(\"NPS\") || 0\n",
              "                    },\n",
              "                    health_insurance: formData.get(\"health_insurance\") === \"on\"\n",
              "                })\n",
              "            });\n",
              "\n",
              "            const data = await response.json();\n",
              "            document.getElementById(\"result\").innerHTML = `\n",
              "                <h3>Results</h3>\n",
              "                <p>Taxable Income: ₹${data.taxable_income.toLocaleString()}</p>\n",
              "                <p>Total Tax: ₹${data.total_tax.toLocaleString()}</p>\n",
              "                <p>Effective Rate: ${data.effective_rate.toFixed(2)}%</p>\n",
              "                <h4>Deductions Applied:</h4>\n",
              "                <ul>\n",
              "                    <li>80C: ₹${data.deductions['80C'].toLocaleString()}</li>\n",
              "                    <li>80D: ₹${data.deductions['80D'].toLocaleString()}</li>\n",
              "                    <li>NPS: ₹${data.deductions['NPS'].toLocaleString()}</li>\n",
              "                </ul>\n",
              "            `;\n",
              "        };\n",
              "    </script>\n",
              "</body>\n",
              "</html>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# In Colab (after restarting runtime)\n",
        "!npm install -g localtunnel\n",
        "!lt --port 8000 --subdomain taxapi  # Will give you: https://taxapi.loca.lt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KDrDQATz9wT",
        "outputId": "53987f55-fe74-43b1-fb05-5ea4fa175559"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K⠦\u001b[1G\u001b[0K⠧\u001b[1G\u001b[0K⠇\u001b[1G\u001b[0K⠏\u001b[1G\u001b[0K⠋\u001b[1G\u001b[0K⠙\u001b[1G\u001b[0K⠹\u001b[1G\u001b[0K⠸\u001b[1G\u001b[0K⠼\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "added 22 packages in 3s\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K3 packages are looking for funding\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0K  run `npm fund` for details\n",
            "\u001b[1G\u001b[0K⠴\u001b[1G\u001b[0Kyour url is: https://taxapi.loca.lt\n"
          ]
        }
      ]
    }
  ]
}